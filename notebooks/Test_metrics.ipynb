{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/2211.10295.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-19 19:24:12.785704: Importing os...\n",
      "2023-10-19 19:24:12.785798: Importing sys...\n",
      "Visible devices: [1]\n",
      "2023-10-19 19:24:12.786000: Importing timer from timeit...\n",
      "2023-10-19 19:24:12.786054: Setting env variables for tf import (only device [1] will be available)...\n",
      "2023-10-19 19:24:12.786150: Importing numpy...\n",
      "2023-10-19 19:24:12.889398: Importing matplotlib...\n",
      "2023-10-19 19:24:13.139498: Importing h5py...\n",
      "2023-10-19 19:24:13.154910: Importing importlib.util...\n",
      "2023-10-19 19:24:13.154990: Importing json...\n",
      "2023-10-19 19:24:13.155042: Importing pandas...\n",
      "2023-10-19 19:24:13.395322: Importing random...\n",
      "2023-10-19 19:24:13.395476: Importing scipy utils...\n",
      "2023-10-19 19:24:13.637885: Importing subprocess...\n",
      "2023-10-19 19:24:13.638023: Importing tensorflow...\n",
      "Tensorflow version: 2.9.3\n",
      "2023-10-19 19:24:15.120639: Importing tensorflow_probability...\n",
      "Tensorflow probability version: 0.13.0\n",
      "2023-10-19 19:24:15.556306: Importing timeit...\n",
      "2023-10-19 19:24:15.556427: Importing tqdm...\n",
      "2023-10-19 19:24:15.560491: Importing typing...\n",
      "2023-10-19 19:24:15.560604: Setting tf configs...\n",
      "2023-10-19 19:24:15.602846: Importing GMetrics module...\n",
      "2023-10-19 19:24:15.655146: Importing jetnet.evaluation.gen_metrics module...\n",
      "Successfully loaded GPU model: Tesla V100-PCIE-32GB\n",
      "2023-10-19 19:24:18.536281: All done.\n"
     ]
    }
   ],
   "source": [
    "visible_devices = [1]\n",
    "import datetime\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing os...\")\n",
    "import os\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing sys...\")\n",
    "import sys\n",
    "if not any(\"ipykernel\" in arg for arg in sys.argv):\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing and initializing argparse...\")\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-v\", \"--visible_devices\", help=\"Set visible devices\", nargs='*', type=list, default=visible_devices)\n",
    "    args = parser.parse_args()\n",
    "    visible_devices = args.visible_devices if args.visible_devices else visible_devices\n",
    "    if len(visible_devices) == 0:\n",
    "        visible_devices = int(visible_devices) # type: ignore\n",
    "    elif len(visible_devices) == 1:\n",
    "        if len(visible_devices[0]) == 0: # type: ignore\n",
    "            visible_devices = int(visible_devices[0])\n",
    "        else:\n",
    "            visible_devices = [int(i) for i in visible_devices[0]] # type: ignore\n",
    "    else:\n",
    "        visible_devices = [int(i) for i in visible_devices]\n",
    "print(\"Visible devices:\", visible_devices)\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing timer from timeit...\")\n",
    "from timeit import default_timer as timer\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Setting env variables for tf import (only device\", visible_devices, \"will be available)...\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([str(i) for i in visible_devices]) # type: ignore\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2'\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing numpy...\")\n",
    "import numpy as np\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing matplotlib...\")\n",
    "from matplotlib import pyplot as plt\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing h5py...\")\n",
    "import h5py\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing importlib.util...\")\n",
    "import importlib.util\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing json...\")\n",
    "import json\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing pandas...\")\n",
    "import pandas as pd\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing random...\")\n",
    "import random\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing scipy utils...\")\n",
    "from scipy.stats import norm, chi2, kstwo, kstwobign, ks_2samp, moment\n",
    "from scipy.special import kolmogorov\n",
    "from scipy.optimize import minimize, curve_fit, root, bisect\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing subprocess...\")\n",
    "import subprocess\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing tensorflow...\")\n",
    "import tensorflow as tf # type: ignore\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing tensorflow_probability...\")\n",
    "import tensorflow_probability as tfp # type: ignore\n",
    "tfd = tfp.distributions\n",
    "print(\"Tensorflow probability version:\", tfp.__version__)\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing timeit...\")\n",
    "from timeit import default_timer as timer\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing tqdm...\")\n",
    "from tqdm import tqdm\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing typing...\")\n",
    "from typing import List, Tuple, Dict, Callable, Union, Optional, Any, Type\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Setting tf configs...\")\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu_device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_device, True)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing GMetrics module...\")\n",
    "\n",
    "sys.path.insert(0,'../utils_func/')\n",
    "import MixtureDistributions # type: ignore\n",
    "\n",
    "sys.path.insert(0,'../../')\n",
    "import GenerativeModelsMetrics as GMetrics # type: ignore\n",
    "from GenerativeModelsMetrics.utils import se_mean, se_std # type: ignore\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing jetnet.evaluation.gen_metrics module...\")\n",
    "from jetnet.evaluation import gen_metrics as JMetrics # type: ignore\n",
    "\n",
    "paper_fig_dir = \"../../../NormalizingFlows/papers/NFHD/figures/\"\n",
    "\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        gpu_info = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=gpu_name\", \"--format=csv,noheader\"]).decode('utf-8')\n",
    "        return gpu_info.strip().split('\\n')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "gpu_models = get_gpu_info()\n",
    "if gpu_models:\n",
    "    training_device = gpu_models[eval(os.environ[\"CUDA_VISIBLE_DEVICES\"])]\n",
    "    print(\"Successfully loaded GPU model: {}\".format(training_device))\n",
    "else:\n",
    "    training_device = 'undetermined'\n",
    "    print(\"Failed to load GPU model. Defaulting to 'undetermined'.\")\n",
    "    \n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"All done.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Define distribution and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float64'> <dtype: 'float64'>\n",
      "Types of distributions:  <class 'tensorflow_probability.python.distributions.independent.Independent'> <class 'tensorflow_probability.python.distributions.independent.Independent'>\n",
      "Dtypes of distributions:  <dtype: 'float64'> <dtype: 'float64'>\n",
      "Batch shapes of distributions:  () ()\n",
      "Event shapes of distributions:  (10,) (10,)\n"
     ]
    }
   ],
   "source": [
    "ndims = 10\n",
    "seed = 0\n",
    "epsilon = 0.005\n",
    "loc1 = np.array(np.zeros(ndims,dtype=np.float64),dtype=np.float64)\n",
    "scale1 = np.array(np.ones(ndims,dtype=np.float64),dtype=np.float64)\n",
    "loc2 = np.array(np.random.uniform(-epsilon,epsilon,ndims),dtype=np.float64)\n",
    "scale2 = np.array(np.random.uniform(1-epsilon,1+epsilon,ndims),dtype=np.float64)\n",
    "dist_1 = tfd.Independent(tfp.distributions.Normal(loc=loc1, scale=scale1), reinterpreted_batch_ndims=1)\n",
    "dist_2 = tfd.Independent(tfp.distributions.Normal(loc=loc2, scale=scale2), reinterpreted_batch_ndims=1)\n",
    "print(dist_1.dtype, dist_2.dtype)\n",
    "print('Types of distributions: ', type(dist_1), type(dist_2))\n",
    "print('Dtypes of distributions: ', dist_1.dtype, dist_2.dtype)\n",
    "print('Batch shapes of distributions: ', dist_1.batch_shape, dist_2.batch_shape)\n",
    "print('Event shapes of distributions: ', dist_1.event_shape, dist_2.event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ncomp = 3\n",
    "#ndims = 10\n",
    "#seed = 0\n",
    "#epsilon = 0.005\n",
    "#loc1 = np.array(np.zeros([ncomp,ndims],dtype=np.float64),dtype=np.float64)\n",
    "#scale1 = np.array(np.ones([ncomp,ndims],dtype=np.float64),dtype=np.float64)\n",
    "#loc2 = np.array(np.random.uniform(-epsilon,epsilon,[ncomp,ndims]),dtype=np.float64)\n",
    "#scale2 = np.array(np.random.uniform(-epsilon,epsilon,[ncomp,ndims]),dtype=np.float64)\n",
    "#comp1 = []\n",
    "#for i in range(ncomp):\n",
    "#    comp1.append(tfd.MultivariateNormalDiag(loc=loc1[i],scale_diag=scale1[i]))\n",
    "#comp2 = []\n",
    "#for i in range(ncomp):\n",
    "#    comp2.append(tfd.MultivariateNormalDiag(loc=loc2[i],scale_diag=scale2[i]))\n",
    "#probs = np.random.sample(ncomp)\n",
    "#dist_1 = tfd.Mixture(\n",
    "#            cat=tfd.Categorical(probs = probs),\n",
    "#            components = comp1,\n",
    "#            validate_args = True)\n",
    "#dist_2 = tfd.Mixture(\n",
    "#            cat=tfd.Categorical(probs = probs),\n",
    "#            components = comp2,\n",
    "#            validate_args = True)\n",
    "#print('Types of distributions: ', type(dist_1), type(dist_2))\n",
    "#print('Dtypes of distributions: ', dist_1.dtype, dist_2.dtype)\n",
    "#print('Batch shapes of distributions: ', dist_1.batch_shape, dist_2.batch_shape)\n",
    "#print('Event shapes of distributions: ', dist_1.event_shape, dist_2.event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing input distribution...\n",
      "Input distribution is a tfp.distributions.Distribution object.\n",
      "Parsing input distribution...\n",
      "Input distribution is a tfp.distributions.Distribution object.\n",
      "Checking and setting numerical distributions.\n",
      "Resetting dist_num.\n",
      "Resetting dist_num.\n",
      "nsamples 10000000\n",
      "batch_size 100000\n",
      "niter 100\n",
      "niter * batch_size 10000000\n",
      "small_sample False\n"
     ]
    }
   ],
   "source": [
    "TwoSampleTestInputs = GMetrics.TwoSampleTestInputs(dist_1_input = dist_1,\n",
    "                                                   dist_2_input = dist_2,\n",
    "                                                   niter = 100,\n",
    "                                                   batch_size_test = 100000,\n",
    "                                                   batch_size_gen = 10000,\n",
    "                                                   small_sample_threshold = 1e7,\n",
    "                                                   dtype_input = tf.float64,\n",
    "                                                   seed_input = 0,\n",
    "                                                   use_tf = True,\n",
    "                                                   mirror_strategy = False,\n",
    "                                                   verbose = True)\n",
    "print(\"nsamples\",TwoSampleTestInputs.nsamples)\n",
    "print(\"batch_size\",TwoSampleTestInputs.batch_size_test)\n",
    "print(\"niter\",TwoSampleTestInputs.niter)\n",
    "print(\"niter * batch_size\",TwoSampleTestInputs.niter*TwoSampleTestInputs.batch_size_test)\n",
    "print(\"small_sample\",TwoSampleTestInputs.small_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "KSTest = GMetrics.KSTest(TwoSampleTestInputs,\n",
    "                         progress_bar = True,\n",
    "                         verbose = True)\n",
    "SKSTest = GMetrics.SKSTest(TwoSampleTestInputs,\n",
    "                           progress_bar = True,\n",
    "                           verbose = True)\n",
    "MultiKSTest = GMetrics.MultiKSTest(TwoSampleTestInputs,\n",
    "                                   progress_bar = True,\n",
    "                                   verbose = True)\n",
    "SWDMetric = GMetrics.SWDMetric(TwoSampleTestInputs,\n",
    "                               progress_bar = True,\n",
    "                               verbose = True)\n",
    "FNMetric = GMetrics.FNMetric(TwoSampleTestInputs,\n",
    "                             progress_bar = True,\n",
    "                             verbose = True)\n",
    "LRMetric = GMetrics.LRMetric(TwoSampleTestInputs,\n",
    "                             progress_bar = True,\n",
    "                             verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute tests Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting KS tests calculation...\n",
      "niter = 10000\n",
      "batch_size = 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running numpy KS tests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:   0%|          | 50/10000 [00:16<58:39,  2.83it/s]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58787/1351260833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mKSTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mKSTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/GenerativeModelsMetrics/ks_metrics.py\u001b[0m in \u001b[0;36mTest_np\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mlist2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 \u001b[0mstatistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mks_2samp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_1_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_2_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mlist1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0mlist2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_9/lib/python3.8/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_9/lib/python3.8/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36mks_2samp\u001b[0;34m(data1, data2, alternative, method)\u001b[0m\n\u001b[1;32m   8115\u001b[0m     \u001b[0mdata_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8116\u001b[0m     \u001b[0;31m# using searchsorted solves equal data problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8117\u001b[0;31m     \u001b[0mcdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8118\u001b[0m     \u001b[0mcdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8119\u001b[0m     \u001b[0mcddiffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdf1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcdf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_9/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msearchsorted\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_9/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msearchsorted\u001b[0;34m(a, v, side, sorter)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \"\"\"\n\u001b[0;32m-> 1387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'searchsorted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_9/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "KSTest.Test_np()\n",
    "KSTest.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting SKS metric calculation...\n",
      "niter = 10\n",
      "batch_size = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running numpy SKS calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample test calculation completed in 9.414096144028008 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric_lists': array([[0.012 , 0.0131, 0.009 , 0.0129, 0.0168, 0.0116, 0.0102, 0.0264,\n",
       "         0.0191, 0.0077, 0.0114, 0.0159, 0.0092, 0.0095, 0.0144, 0.013 ,\n",
       "         0.0146, 0.0076, 0.0214, 0.0126, 0.0161, 0.0107, 0.0074, 0.0151,\n",
       "         0.0092, 0.0111, 0.0096, 0.005 , 0.0093, 0.0149, 0.0124, 0.0097,\n",
       "         0.0064, 0.018 , 0.012 , 0.0168, 0.0142, 0.0165, 0.0107, 0.0072,\n",
       "         0.0101, 0.0107, 0.0073, 0.0187, 0.0111, 0.0123, 0.0178, 0.01  ,\n",
       "         0.0107, 0.009 , 0.0159, 0.012 , 0.0117, 0.0126, 0.0119, 0.0178,\n",
       "         0.0102, 0.0158, 0.0203, 0.0079, 0.0122, 0.0124, 0.0101, 0.0105,\n",
       "         0.0135, 0.0103, 0.0094, 0.0121, 0.0066, 0.0128, 0.0138, 0.0089,\n",
       "         0.015 , 0.0119, 0.0104, 0.0081, 0.0122, 0.0095, 0.013 , 0.0132,\n",
       "         0.0231, 0.0129, 0.0175, 0.0139, 0.0085, 0.0121, 0.0144, 0.0168,\n",
       "         0.0176, 0.0075, 0.0085, 0.017 , 0.0087, 0.0102, 0.0097, 0.0078,\n",
       "         0.007 , 0.0117, 0.0103, 0.0066],\n",
       "        [0.009 , 0.0077, 0.0093, 0.0176, 0.0136, 0.0123, 0.0173, 0.0107,\n",
       "         0.0121, 0.016 , 0.0167, 0.0201, 0.0154, 0.0102, 0.0073, 0.0157,\n",
       "         0.0145, 0.0089, 0.0182, 0.0136, 0.0111, 0.0135, 0.0174, 0.0179,\n",
       "         0.0112, 0.0091, 0.0191, 0.0084, 0.0164, 0.0138, 0.0075, 0.0132,\n",
       "         0.0184, 0.0118, 0.017 , 0.0117, 0.01  , 0.0131, 0.0196, 0.01  ,\n",
       "         0.0155, 0.0197, 0.0103, 0.0151, 0.0151, 0.0163, 0.012 , 0.0182,\n",
       "         0.0201, 0.0079, 0.0169, 0.0098, 0.017 , 0.0106, 0.0144, 0.0118,\n",
       "         0.01  , 0.0196, 0.0088, 0.0232, 0.0112, 0.016 , 0.0154, 0.0128,\n",
       "         0.0121, 0.0134, 0.013 , 0.0112, 0.0122, 0.0126, 0.0119, 0.0099,\n",
       "         0.0118, 0.0102, 0.0096, 0.0084, 0.0103, 0.0123, 0.0096, 0.0108,\n",
       "         0.0082, 0.0118, 0.0161, 0.0097, 0.0128, 0.0138, 0.011 , 0.007 ,\n",
       "         0.0056, 0.0084, 0.0135, 0.0191, 0.0126, 0.0068, 0.01  , 0.0089,\n",
       "         0.0173, 0.0122, 0.0083, 0.0081],\n",
       "        [0.0092, 0.0098, 0.0104, 0.0092, 0.0111, 0.0131, 0.0157, 0.0079,\n",
       "         0.0084, 0.0121, 0.0085, 0.0077, 0.0107, 0.0088, 0.0119, 0.0096,\n",
       "         0.0093, 0.0091, 0.0078, 0.0091, 0.0087, 0.0107, 0.0176, 0.0104,\n",
       "         0.0098, 0.0097, 0.0076, 0.0095, 0.0114, 0.009 , 0.0135, 0.0135,\n",
       "         0.0123, 0.0104, 0.009 , 0.0083, 0.0101, 0.0072, 0.01  , 0.0097,\n",
       "         0.0095, 0.0126, 0.0062, 0.0117, 0.0074, 0.0116, 0.009 , 0.0089,\n",
       "         0.0102, 0.0147, 0.0121, 0.0121, 0.0076, 0.0091, 0.0122, 0.011 ,\n",
       "         0.0123, 0.0148, 0.0105, 0.0107, 0.0121, 0.0135, 0.0112, 0.0069,\n",
       "         0.0075, 0.0097, 0.0078, 0.0112, 0.0097, 0.0095, 0.0111, 0.0089,\n",
       "         0.0072, 0.0063, 0.0072, 0.0094, 0.0116, 0.0101, 0.0133, 0.014 ,\n",
       "         0.0121, 0.0087, 0.009 , 0.0062, 0.0139, 0.0055, 0.0087, 0.007 ,\n",
       "         0.0079, 0.008 , 0.0103, 0.0109, 0.0081, 0.0095, 0.008 , 0.0134,\n",
       "         0.013 , 0.0122, 0.0144, 0.0115],\n",
       "        [0.0072, 0.0098, 0.0083, 0.0065, 0.0149, 0.0134, 0.0152, 0.0099,\n",
       "         0.0143, 0.0147, 0.0087, 0.011 , 0.0118, 0.0098, 0.011 , 0.0158,\n",
       "         0.0111, 0.0136, 0.0113, 0.0084, 0.0111, 0.0132, 0.0082, 0.011 ,\n",
       "         0.0193, 0.0092, 0.0149, 0.012 , 0.0151, 0.0119, 0.0168, 0.0128,\n",
       "         0.0099, 0.0096, 0.0165, 0.0102, 0.0142, 0.0119, 0.0098, 0.0176,\n",
       "         0.0078, 0.0106, 0.0108, 0.014 , 0.011 , 0.0098, 0.0084, 0.0129,\n",
       "         0.0149, 0.0111, 0.0084, 0.0161, 0.0133, 0.008 , 0.0144, 0.0107,\n",
       "         0.015 , 0.0125, 0.0071, 0.008 , 0.0142, 0.0103, 0.0139, 0.012 ,\n",
       "         0.0111, 0.0098, 0.0088, 0.0117, 0.0127, 0.0084, 0.0141, 0.0092,\n",
       "         0.0093, 0.0094, 0.008 , 0.0077, 0.0065, 0.0095, 0.0106, 0.0079,\n",
       "         0.0096, 0.0148, 0.0139, 0.0165, 0.0082, 0.0129, 0.0135, 0.0137,\n",
       "         0.0142, 0.0099, 0.0111, 0.0186, 0.0155, 0.0084, 0.0092, 0.0098,\n",
       "         0.012 , 0.009 , 0.0071, 0.0109],\n",
       "        [0.0121, 0.0144, 0.0085, 0.0125, 0.0147, 0.0141, 0.0161, 0.0121,\n",
       "         0.0087, 0.012 , 0.0092, 0.0132, 0.0106, 0.0142, 0.0095, 0.0199,\n",
       "         0.017 , 0.0175, 0.0122, 0.0094, 0.0125, 0.0168, 0.0094, 0.0072,\n",
       "         0.0064, 0.0076, 0.0111, 0.0119, 0.0144, 0.0079, 0.0137, 0.0095,\n",
       "         0.0087, 0.0083, 0.0132, 0.0108, 0.0111, 0.0094, 0.0083, 0.0124,\n",
       "         0.0091, 0.0076, 0.0107, 0.0081, 0.0108, 0.0167, 0.0148, 0.0108,\n",
       "         0.0094, 0.012 , 0.0138, 0.0131, 0.0153, 0.0105, 0.0237, 0.0127,\n",
       "         0.0106, 0.0142, 0.0095, 0.0196, 0.0093, 0.0101, 0.0165, 0.0145,\n",
       "         0.0149, 0.0126, 0.0119, 0.0195, 0.0086, 0.0134, 0.0116, 0.0188,\n",
       "         0.0157, 0.0134, 0.0147, 0.0153, 0.0101, 0.0082, 0.0143, 0.0114,\n",
       "         0.0112, 0.0115, 0.0117, 0.0086, 0.0086, 0.0203, 0.0117, 0.0081,\n",
       "         0.0135, 0.0081, 0.0173, 0.0113, 0.0133, 0.0098, 0.0104, 0.0134,\n",
       "         0.01  , 0.015 , 0.01  , 0.0078],\n",
       "        [0.011 , 0.0168, 0.008 , 0.0151, 0.0082, 0.0227, 0.0204, 0.0083,\n",
       "         0.0126, 0.0153, 0.0148, 0.0089, 0.0102, 0.0249, 0.0109, 0.0175,\n",
       "         0.0097, 0.0118, 0.0119, 0.0169, 0.014 , 0.0094, 0.0076, 0.0107,\n",
       "         0.0177, 0.0168, 0.0101, 0.01  , 0.0138, 0.0092, 0.0064, 0.0112,\n",
       "         0.0095, 0.0079, 0.0156, 0.0224, 0.0064, 0.0153, 0.0144, 0.0175,\n",
       "         0.0107, 0.0147, 0.0116, 0.0074, 0.0116, 0.0193, 0.0153, 0.0102,\n",
       "         0.0152, 0.0071, 0.0216, 0.0123, 0.0154, 0.0105, 0.0106, 0.0151,\n",
       "         0.0171, 0.0071, 0.0116, 0.0114, 0.0095, 0.011 , 0.0109, 0.0108,\n",
       "         0.0084, 0.0057, 0.0101, 0.0123, 0.0107, 0.0085, 0.009 , 0.0096,\n",
       "         0.0061, 0.0106, 0.0158, 0.0079, 0.0072, 0.0165, 0.01  , 0.0092,\n",
       "         0.0078, 0.012 , 0.017 , 0.0139, 0.0102, 0.0088, 0.0143, 0.0109,\n",
       "         0.0152, 0.0101, 0.0171, 0.0088, 0.0087, 0.0105, 0.0098, 0.0086,\n",
       "         0.0113, 0.0075, 0.0137, 0.0138],\n",
       "        [0.0082, 0.0067, 0.0109, 0.0118, 0.0152, 0.0148, 0.0099, 0.0132,\n",
       "         0.013 , 0.009 , 0.0115, 0.0118, 0.0138, 0.0196, 0.0079, 0.007 ,\n",
       "         0.0113, 0.0104, 0.0106, 0.0104, 0.0141, 0.0118, 0.0104, 0.0081,\n",
       "         0.0138, 0.0094, 0.0122, 0.0106, 0.0147, 0.01  , 0.0114, 0.0069,\n",
       "         0.0109, 0.0114, 0.0107, 0.0098, 0.0142, 0.0118, 0.0164, 0.0168,\n",
       "         0.0076, 0.0151, 0.0094, 0.01  , 0.0239, 0.0077, 0.0109, 0.0116,\n",
       "         0.0088, 0.0137, 0.0133, 0.0128, 0.0143, 0.0067, 0.0109, 0.0077,\n",
       "         0.0081, 0.0085, 0.0085, 0.0148, 0.0123, 0.0088, 0.0113, 0.0145,\n",
       "         0.0088, 0.0098, 0.0131, 0.016 , 0.0127, 0.0076, 0.0134, 0.0113,\n",
       "         0.0128, 0.0088, 0.0089, 0.0106, 0.0102, 0.0061, 0.0138, 0.007 ,\n",
       "         0.0093, 0.0133, 0.0134, 0.01  , 0.0114, 0.0187, 0.0115, 0.0081,\n",
       "         0.0093, 0.0112, 0.0096, 0.0143, 0.0165, 0.0068, 0.0096, 0.0115,\n",
       "         0.0141, 0.0167, 0.0075, 0.0107],\n",
       "        [0.012 , 0.0156, 0.0091, 0.0116, 0.021 , 0.0149, 0.0108, 0.0096,\n",
       "         0.0122, 0.0105, 0.0127, 0.0115, 0.0265, 0.0127, 0.0153, 0.0166,\n",
       "         0.0124, 0.0151, 0.0134, 0.011 , 0.0194, 0.0109, 0.0178, 0.0131,\n",
       "         0.0194, 0.0124, 0.0082, 0.022 , 0.0101, 0.0136, 0.0121, 0.0152,\n",
       "         0.0184, 0.0109, 0.0193, 0.0114, 0.0079, 0.0186, 0.0214, 0.0117,\n",
       "         0.0116, 0.0155, 0.023 , 0.0079, 0.0171, 0.0111, 0.0078, 0.0121,\n",
       "         0.0128, 0.0117, 0.0095, 0.0114, 0.0117, 0.0097, 0.009 , 0.0085,\n",
       "         0.007 , 0.014 , 0.0111, 0.0231, 0.0143, 0.0082, 0.016 , 0.0128,\n",
       "         0.012 , 0.0093, 0.0146, 0.0133, 0.0125, 0.015 , 0.0102, 0.0106,\n",
       "         0.0114, 0.0122, 0.007 , 0.0118, 0.007 , 0.011 , 0.011 , 0.0099,\n",
       "         0.0063, 0.019 , 0.0169, 0.0126, 0.0137, 0.011 , 0.0089, 0.011 ,\n",
       "         0.0186, 0.0177, 0.0068, 0.0122, 0.0116, 0.0253, 0.0148, 0.0067,\n",
       "         0.0142, 0.0146, 0.0153, 0.0157],\n",
       "        [0.0173, 0.0114, 0.0203, 0.0235, 0.0105, 0.0129, 0.0131, 0.0102,\n",
       "         0.0153, 0.0122, 0.0197, 0.0257, 0.0204, 0.0119, 0.0178, 0.0094,\n",
       "         0.0127, 0.0146, 0.0161, 0.0155, 0.0151, 0.0161, 0.0101, 0.0137,\n",
       "         0.0152, 0.0203, 0.0146, 0.011 , 0.0171, 0.0127, 0.0102, 0.0156,\n",
       "         0.0271, 0.0166, 0.0168, 0.0183, 0.0214, 0.0151, 0.0217, 0.0214,\n",
       "         0.0181, 0.0206, 0.0193, 0.0124, 0.0216, 0.0202, 0.0279, 0.0141,\n",
       "         0.0067, 0.0207, 0.0201, 0.0176, 0.0085, 0.0094, 0.0209, 0.0228,\n",
       "         0.0168, 0.0155, 0.0217, 0.0148, 0.0105, 0.017 , 0.0148, 0.014 ,\n",
       "         0.0086, 0.0072, 0.0157, 0.0104, 0.0168, 0.0135, 0.0141, 0.0326,\n",
       "         0.0278, 0.0253, 0.0071, 0.0178, 0.0268, 0.0167, 0.023 , 0.0166,\n",
       "         0.0109, 0.014 , 0.0136, 0.0088, 0.0105, 0.0146, 0.0267, 0.0252,\n",
       "         0.0111, 0.0242, 0.0116, 0.0108, 0.0175, 0.0173, 0.0145, 0.0096,\n",
       "         0.0254, 0.0118, 0.015 , 0.0092],\n",
       "        [0.0105, 0.0107, 0.0076, 0.0073, 0.0152, 0.0112, 0.0132, 0.0077,\n",
       "         0.0095, 0.0114, 0.0097, 0.0091, 0.016 , 0.0094, 0.0088, 0.0085,\n",
       "         0.0105, 0.0145, 0.009 , 0.0103, 0.0118, 0.0113, 0.0107, 0.01  ,\n",
       "         0.0109, 0.0142, 0.0074, 0.011 , 0.0118, 0.0111, 0.0097, 0.0152,\n",
       "         0.0093, 0.0101, 0.0112, 0.011 , 0.0167, 0.0072, 0.0109, 0.0118,\n",
       "         0.0103, 0.012 , 0.0141, 0.0102, 0.0092, 0.007 , 0.0097, 0.0067,\n",
       "         0.0117, 0.0184, 0.0086, 0.0118, 0.0128, 0.0138, 0.0094, 0.0141,\n",
       "         0.0082, 0.0149, 0.0099, 0.0148, 0.007 , 0.0071, 0.006 , 0.0092,\n",
       "         0.0117, 0.0108, 0.0132, 0.012 , 0.0116, 0.0151, 0.0097, 0.0103,\n",
       "         0.0124, 0.0172, 0.0135, 0.0138, 0.0106, 0.0127, 0.0107, 0.014 ,\n",
       "         0.0177, 0.0099, 0.0125, 0.0103, 0.0095, 0.0074, 0.008 , 0.0118,\n",
       "         0.0169, 0.0093, 0.0094, 0.0105, 0.0123, 0.0137, 0.0077, 0.0068,\n",
       "         0.0185, 0.0068, 0.017 , 0.0148]]),\n",
       " 'metric_means': array([0.012222, 0.012846, 0.010185, 0.011506, 0.012179, 0.012074,\n",
       "        0.01138 , 0.013169, 0.016289, 0.011204]),\n",
       " 'metric_stds': array([0.00385543, 0.00372495, 0.00229427, 0.00287704, 0.00334127,\n",
       "        0.00396617, 0.00308425, 0.00417015, 0.00542079, 0.00285853])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SKSTest.Test_np(nslices = 100)\n",
    "SKSTest.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiKS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting MultiKS tests calculation...\n",
      "niter = 10\n",
      "batch_size = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running numpy MultiKS tests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 10/10 [02:10<00:00, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample test calculation completed in 130.6175842662342 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric_list': array([0.0161, 0.0156, 0.0156, 0.0156, 0.0165, 0.018 , 0.0127, 0.0146,\n",
       "        0.027 , 0.0124])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiKSTest.Test_np()\n",
    "MultiKSTest.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWD Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting SWD metric calculation...\n",
      "niter = 10\n",
      "batch_size = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running numpy SKS calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 10/10 [00:08<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample test calculation completed in 8.52153637027368 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric_lists': array([[0.02016129, 0.00889164, 0.01306561, 0.01663194, 0.02424905,\n",
       "         0.01346312, 0.01571159, 0.03259101, 0.03409661, 0.01039257,\n",
       "         0.01292748, 0.02520791, 0.01266434, 0.01659473, 0.01732404,\n",
       "         0.02094398, 0.02188637, 0.0164312 , 0.02539031, 0.01953624,\n",
       "         0.02739648, 0.00937295, 0.01237911, 0.02225105, 0.0159113 ,\n",
       "         0.01689114, 0.01132221, 0.01080084, 0.01390396, 0.02176115,\n",
       "         0.01449561, 0.01740526, 0.01008219, 0.02921705, 0.01679585,\n",
       "         0.01945302, 0.02223573, 0.02973452, 0.01013254, 0.01325689,\n",
       "         0.01727872, 0.02133985, 0.01197638, 0.03067714, 0.01282283,\n",
       "         0.01586708, 0.02630358, 0.01502051, 0.02385536, 0.01206243,\n",
       "         0.02302192, 0.01335935, 0.01997904, 0.02294094, 0.01380886,\n",
       "         0.02197572, 0.01350959, 0.03090048, 0.03423895, 0.01686758,\n",
       "         0.02428383, 0.01249675, 0.01777701, 0.01846186, 0.01962254,\n",
       "         0.01224733, 0.01344869, 0.01508842, 0.00949262, 0.02360916,\n",
       "         0.0153156 , 0.01731805, 0.02808986, 0.02072979, 0.01746549,\n",
       "         0.01248204, 0.01692395, 0.01613902, 0.02293158, 0.01627001,\n",
       "         0.03529355, 0.02407008, 0.02119517, 0.01412404, 0.01113289,\n",
       "         0.01986052, 0.02742528, 0.02366736, 0.02924572, 0.01134601,\n",
       "         0.01271077, 0.02538442, 0.01511031, 0.01224453, 0.01574697,\n",
       "         0.01208661, 0.01077109, 0.01988113, 0.02126613, 0.01003372],\n",
       "        [0.0106688 , 0.01409217, 0.01379157, 0.02804544, 0.01836361,\n",
       "         0.01578641, 0.03336537, 0.01271368, 0.01888153, 0.02396596,\n",
       "         0.02477405, 0.01874231, 0.02423667, 0.01435091, 0.0103534 ,\n",
       "         0.02553668, 0.0274901 , 0.01199271, 0.02199861, 0.01677546,\n",
       "         0.01657877, 0.01967784, 0.0305349 , 0.02571854, 0.02156044,\n",
       "         0.01371487, 0.03404837, 0.01241529, 0.02487356, 0.02012005,\n",
       "         0.01515989, 0.02262454, 0.03705227, 0.02591248, 0.03265455,\n",
       "         0.01679102, 0.01533415, 0.01905924, 0.02990921, 0.01121603,\n",
       "         0.02054733, 0.02994257, 0.01433437, 0.02132026, 0.02134561,\n",
       "         0.02394075, 0.01855468, 0.02526586, 0.03161889, 0.01293696,\n",
       "         0.02943474, 0.01112283, 0.02601861, 0.01551687, 0.0250389 ,\n",
       "         0.01744786, 0.01373706, 0.02466555, 0.01347214, 0.03055402,\n",
       "         0.01604109, 0.02166334, 0.02153863, 0.01578685, 0.01636026,\n",
       "         0.01982986, 0.02051823, 0.01736701, 0.01773986, 0.02109216,\n",
       "         0.01755225, 0.01632424, 0.02545666, 0.01511233, 0.01710852,\n",
       "         0.01087745, 0.02008455, 0.01387322, 0.01427197, 0.01472891,\n",
       "         0.01430699, 0.01708794, 0.02608324, 0.01617887, 0.02190098,\n",
       "         0.02063985, 0.01946595, 0.01343936, 0.00924406, 0.01575044,\n",
       "         0.02088818, 0.03104707, 0.02247405, 0.01472483, 0.01680688,\n",
       "         0.01418647, 0.0224871 , 0.0155995 , 0.01097081, 0.01037117],\n",
       "        [0.01146177, 0.0124606 , 0.01951939, 0.01162804, 0.01525165,\n",
       "         0.01736236, 0.0155539 , 0.01003783, 0.01072717, 0.01356052,\n",
       "         0.01177494, 0.01104849, 0.01656705, 0.01040106, 0.01749173,\n",
       "         0.01216815, 0.01208504, 0.01422732, 0.01221455, 0.0144739 ,\n",
       "         0.01121146, 0.0142243 , 0.02127105, 0.01937789, 0.01382138,\n",
       "         0.0098039 , 0.00984269, 0.01341505, 0.01303777, 0.01194385,\n",
       "         0.01550798, 0.01368423, 0.01831595, 0.01875525, 0.01140946,\n",
       "         0.01464516, 0.01755402, 0.01092518, 0.00932202, 0.01346671,\n",
       "         0.012033  , 0.02086427, 0.01156065, 0.01189254, 0.0103761 ,\n",
       "         0.01549666, 0.01067349, 0.01755985, 0.01491112, 0.01869664,\n",
       "         0.0122747 , 0.01329055, 0.01574367, 0.01503319, 0.01560959,\n",
       "         0.01258909, 0.01792953, 0.01344884, 0.01553407, 0.01606596,\n",
       "         0.01521304, 0.014959  , 0.01638567, 0.01009172, 0.01114328,\n",
       "         0.01352735, 0.01262887, 0.01932731, 0.01213129, 0.01310018,\n",
       "         0.015574  , 0.01181385, 0.00865758, 0.00810025, 0.0113997 ,\n",
       "         0.01580239, 0.01950369, 0.01548007, 0.01594893, 0.01746178,\n",
       "         0.01689226, 0.01090643, 0.01536997, 0.00889655, 0.01210043,\n",
       "         0.0085248 , 0.00968501, 0.01095201, 0.01303478, 0.0124392 ,\n",
       "         0.01904592, 0.01276175, 0.01072984, 0.01065595, 0.01196558,\n",
       "         0.02632256, 0.015589  , 0.01720475, 0.01292606, 0.0192484 ],\n",
       "        [0.0113376 , 0.01171245, 0.01029129, 0.00848822, 0.0228822 ,\n",
       "         0.01194278, 0.02216207, 0.01871761, 0.02259394, 0.01782744,\n",
       "         0.01489288, 0.01822559, 0.01959322, 0.01457329, 0.02198788,\n",
       "         0.02303345, 0.01491924, 0.02152125, 0.02407654, 0.00915148,\n",
       "         0.01264602, 0.01587642, 0.01258632, 0.01074711, 0.02823169,\n",
       "         0.0171863 , 0.02590748, 0.02085358, 0.01779316, 0.01665649,\n",
       "         0.01557513, 0.01350031, 0.02014301, 0.01572535, 0.01701112,\n",
       "         0.01437776, 0.0229441 , 0.01635943, 0.0160059 , 0.02078617,\n",
       "         0.01254265, 0.01429569, 0.01922115, 0.0194993 , 0.01708274,\n",
       "         0.01095265, 0.01353809, 0.02292272, 0.02145827, 0.01460651,\n",
       "         0.00956228, 0.02839932, 0.02182748, 0.01183295, 0.02447336,\n",
       "         0.01200652, 0.02957849, 0.02150824, 0.01346965, 0.01247194,\n",
       "         0.02306691, 0.01931925, 0.0235762 , 0.02198018, 0.02067625,\n",
       "         0.01376874, 0.01053711, 0.01876604, 0.01976232, 0.01307439,\n",
       "         0.01733347, 0.01632883, 0.01179259, 0.0150183 , 0.01079281,\n",
       "         0.01249482, 0.01019786, 0.01052193, 0.02013604, 0.01809436,\n",
       "         0.01506314, 0.02283473, 0.0222705 , 0.02368942, 0.0161937 ,\n",
       "         0.01780763, 0.02170129, 0.0168516 , 0.01418454, 0.01337849,\n",
       "         0.01696174, 0.02835035, 0.0226393 , 0.01611645, 0.0121197 ,\n",
       "         0.01331024, 0.01809564, 0.01545993, 0.01109494, 0.0153381 ],\n",
       "        [0.01593843, 0.01864272, 0.01315577, 0.01946641, 0.02218054,\n",
       "         0.02138812, 0.02615237, 0.02103106, 0.01389127, 0.01527819,\n",
       "         0.01255604, 0.02074163, 0.01369506, 0.02071741, 0.0142333 ,\n",
       "         0.02849316, 0.02627271, 0.02133044, 0.01809215, 0.0145946 ,\n",
       "         0.01731176, 0.02089127, 0.0187683 , 0.01197354, 0.00928165,\n",
       "         0.01081317, 0.02450491, 0.01815709, 0.02054759, 0.0133333 ,\n",
       "         0.01852578, 0.01394685, 0.01421667, 0.00997899, 0.02234648,\n",
       "         0.01433686, 0.01472982, 0.0144449 , 0.0151933 , 0.021401  ,\n",
       "         0.01581257, 0.01250836, 0.0152137 , 0.01293049, 0.01535096,\n",
       "         0.02424591, 0.02384089, 0.01202806, 0.0107201 , 0.01391607,\n",
       "         0.02292375, 0.01260102, 0.02654762, 0.01596007, 0.02908874,\n",
       "         0.02230624, 0.01353799, 0.01603098, 0.01605844, 0.0232389 ,\n",
       "         0.01566176, 0.01568228, 0.03028509, 0.02476191, 0.0151463 ,\n",
       "         0.01708421, 0.01263415, 0.02743944, 0.01217235, 0.02672814,\n",
       "         0.01554927, 0.0257044 , 0.02132352, 0.02654301, 0.01454275,\n",
       "         0.01726671, 0.0162992 , 0.01341563, 0.02147879, 0.01844528,\n",
       "         0.01799498, 0.01991241, 0.01667428, 0.00962642, 0.01534666,\n",
       "         0.02039968, 0.0106725 , 0.01112081, 0.01583789, 0.01265929,\n",
       "         0.02182921, 0.01285559, 0.01823916, 0.01090283, 0.0176344 ,\n",
       "         0.01994776, 0.01004297, 0.02023748, 0.01317602, 0.01178687],\n",
       "        [0.01721689, 0.01574053, 0.01321215, 0.01911279, 0.00844169,\n",
       "         0.0250963 , 0.02383785, 0.01232599, 0.0212534 , 0.02216516,\n",
       "         0.02197506, 0.01380746, 0.01566964, 0.02639465, 0.01313908,\n",
       "         0.02241652, 0.0117134 , 0.02121483, 0.01289258, 0.02275672,\n",
       "         0.01925759, 0.01718879, 0.00909008, 0.01362738, 0.0279534 ,\n",
       "         0.02765492, 0.014787  , 0.0165613 , 0.01720956, 0.01295866,\n",
       "         0.00947559, 0.01616456, 0.01102176, 0.0101183 , 0.02104805,\n",
       "         0.02217811, 0.00973346, 0.02454609, 0.01840055, 0.02382571,\n",
       "         0.01267653, 0.02136   , 0.01332484, 0.00890494, 0.01698398,\n",
       "         0.02479833, 0.02314276, 0.01371336, 0.01923959, 0.01079575,\n",
       "         0.0291675 , 0.01417489, 0.02434117, 0.02055671, 0.01126784,\n",
       "         0.01525596, 0.02567216, 0.00929644, 0.01343729, 0.01974261,\n",
       "         0.01596305, 0.01510832, 0.01550486, 0.01335815, 0.01363772,\n",
       "         0.01000865, 0.01455058, 0.0154954 , 0.01783595, 0.01488707,\n",
       "         0.01236969, 0.01003338, 0.00996562, 0.0154049 , 0.02289781,\n",
       "         0.00949092, 0.01059834, 0.0214368 , 0.01336238, 0.00993645,\n",
       "         0.01319093, 0.01599163, 0.02282865, 0.02026003, 0.01537396,\n",
       "         0.01277198, 0.01748981, 0.01523283, 0.02525936, 0.0142387 ,\n",
       "         0.02056257, 0.01021086, 0.01646777, 0.01568461, 0.0114016 ,\n",
       "         0.01423818, 0.0159454 , 0.01115089, 0.01568321, 0.02047633],\n",
       "        [0.01188801, 0.00893974, 0.01383617, 0.01080542, 0.01710404,\n",
       "         0.02642554, 0.01530339, 0.01952783, 0.01741064, 0.01365712,\n",
       "         0.01636246, 0.01967462, 0.01943921, 0.02084524, 0.01087955,\n",
       "         0.01243811, 0.01998995, 0.01289774, 0.01971991, 0.01421611,\n",
       "         0.01618489, 0.01655659, 0.01606793, 0.01145244, 0.01909593,\n",
       "         0.01384574, 0.01678605, 0.01659062, 0.02149808, 0.01139863,\n",
       "         0.02209429, 0.01267611, 0.01388673, 0.01461279, 0.01484615,\n",
       "         0.0157626 , 0.02238538, 0.01715616, 0.02881253, 0.02124566,\n",
       "         0.0131752 , 0.02474739, 0.01381984, 0.01720811, 0.02441096,\n",
       "         0.01118979, 0.01600601, 0.01672812, 0.01309576, 0.01552509,\n",
       "         0.0173331 , 0.02097436, 0.02088573, 0.00863344, 0.01747437,\n",
       "         0.01092704, 0.01186145, 0.01415764, 0.01182589, 0.01979847,\n",
       "         0.01902912, 0.0128368 , 0.01996619, 0.01564891, 0.01335494,\n",
       "         0.01581339, 0.02477293, 0.02857806, 0.01853106, 0.01423282,\n",
       "         0.02425989, 0.01804202, 0.01873758, 0.01024464, 0.01642545,\n",
       "         0.01973569, 0.01892641, 0.01273604, 0.02129022, 0.01235809,\n",
       "         0.01586754, 0.02117655, 0.01750203, 0.0155534 , 0.02225209,\n",
       "         0.02210719, 0.0157406 , 0.01545244, 0.02150146, 0.01705784,\n",
       "         0.01626207, 0.01411263, 0.01887043, 0.00971832, 0.01199071,\n",
       "         0.01226388, 0.02088543, 0.02692998, 0.01309779, 0.0144032 ],\n",
       "        [0.0188529 , 0.02799526, 0.01297086, 0.02040561, 0.02751441,\n",
       "         0.0246958 , 0.01241408, 0.01343769, 0.01490391, 0.01437093,\n",
       "         0.02283236, 0.01721893, 0.03932672, 0.02017491, 0.03569973,\n",
       "         0.02069713, 0.01840198, 0.01785493, 0.01888077, 0.01377476,\n",
       "         0.02485974, 0.01651101, 0.02776093, 0.02379155, 0.02721707,\n",
       "         0.02050766, 0.0085795 , 0.03615519, 0.01617982, 0.02150773,\n",
       "         0.02239764, 0.01615417, 0.02448905, 0.0205052 , 0.03180682,\n",
       "         0.01671238, 0.01341192, 0.02464324, 0.03288043, 0.02044267,\n",
       "         0.01747093, 0.0200033 , 0.03349886, 0.01101987, 0.02368505,\n",
       "         0.01755059, 0.01228589, 0.01983336, 0.02133374, 0.01424792,\n",
       "         0.01252545, 0.01429756, 0.01956255, 0.01385944, 0.01478835,\n",
       "         0.01570132, 0.01127441, 0.01866915, 0.01773323, 0.03222808,\n",
       "         0.02004342, 0.01471944, 0.02366589, 0.01319586, 0.02350006,\n",
       "         0.01375771, 0.02113161, 0.02129998, 0.02447704, 0.02385573,\n",
       "         0.01604043, 0.02056224, 0.01736163, 0.02104668, 0.01316581,\n",
       "         0.01754215, 0.01142979, 0.01312001, 0.01356496, 0.01445492,\n",
       "         0.0104669 , 0.02729602, 0.02304997, 0.01669491, 0.01595348,\n",
       "         0.01739488, 0.01408471, 0.01978432, 0.02287934, 0.02363029,\n",
       "         0.01021418, 0.01781304, 0.01585592, 0.03194479, 0.01598755,\n",
       "         0.0078258 , 0.02732771, 0.01793729, 0.02420027, 0.01561797],\n",
       "        [0.02768888, 0.02365217, 0.0293684 , 0.04355261, 0.018829  ,\n",
       "         0.01292473, 0.02051628, 0.01746134, 0.02890195, 0.02448633,\n",
       "         0.03225396, 0.04981354, 0.03479621, 0.01965301, 0.03318789,\n",
       "         0.01271285, 0.01640195, 0.02394247, 0.0282107 , 0.02975156,\n",
       "         0.02335383, 0.03087549, 0.01813491, 0.02198705, 0.0192913 ,\n",
       "         0.04003494, 0.02742178, 0.0162994 , 0.01916512, 0.02266507,\n",
       "         0.01375949, 0.01728396, 0.0522809 , 0.03461267, 0.02670797,\n",
       "         0.03487568, 0.03668403, 0.02296342, 0.04879878, 0.03498913,\n",
       "         0.03822882, 0.03616609, 0.03906413, 0.01653909, 0.03702529,\n",
       "         0.04331709, 0.0614646 , 0.02359827, 0.01002592, 0.03514125,\n",
       "         0.02342581, 0.03209979, 0.01454944, 0.00998146, 0.03411832,\n",
       "         0.0273961 , 0.03099338, 0.02340067, 0.03490846, 0.01921164,\n",
       "         0.01600673, 0.04003068, 0.01708193, 0.01577348, 0.01204706,\n",
       "         0.01450242, 0.02863771, 0.01525035, 0.03393486, 0.03006883,\n",
       "         0.02781337, 0.0537295 , 0.04855005, 0.06043311, 0.01407064,\n",
       "         0.02589359, 0.04563881, 0.03444445, 0.04291244, 0.0301832 ,\n",
       "         0.01757101, 0.01644686, 0.02304354, 0.01168523, 0.02283617,\n",
       "         0.01792206, 0.04343709, 0.05911269, 0.01511984, 0.04890613,\n",
       "         0.01838601, 0.02095726, 0.03379301, 0.02475194, 0.02485981,\n",
       "         0.01231307, 0.0396168 , 0.02421216, 0.02415554, 0.01468094],\n",
       "        [0.02154472, 0.01206282, 0.01132706, 0.00931274, 0.01878512,\n",
       "         0.0136811 , 0.02308673, 0.01351968, 0.01327875, 0.01905924,\n",
       "         0.01473758, 0.01428401, 0.01892452, 0.01478899, 0.01395846,\n",
       "         0.01153025, 0.01702964, 0.01984824, 0.0098483 , 0.0154062 ,\n",
       "         0.02111157, 0.01106681, 0.01975321, 0.01384855, 0.01497389,\n",
       "         0.01729776, 0.00938096, 0.01554575, 0.02368673, 0.01774649,\n",
       "         0.01524474, 0.02410558, 0.01423481, 0.01730556, 0.01773618,\n",
       "         0.01617986, 0.02732799, 0.01249318, 0.01797373, 0.01801717,\n",
       "         0.01207273, 0.01271266, 0.01949999, 0.01700497, 0.01268028,\n",
       "         0.01009222, 0.01298475, 0.01360152, 0.01347556, 0.01939944,\n",
       "         0.01294641, 0.02062619, 0.0199687 , 0.01807463, 0.01272339,\n",
       "         0.01921028, 0.01160339, 0.01467309, 0.01522795, 0.01893884,\n",
       "         0.01467053, 0.00919998, 0.00838869, 0.02020088, 0.02227195,\n",
       "         0.01560866, 0.0173288 , 0.0177689 , 0.01520874, 0.0255072 ,\n",
       "         0.01402962, 0.01280931, 0.01628017, 0.01680693, 0.02173168,\n",
       "         0.01733478, 0.0136015 , 0.01269587, 0.0135631 , 0.02366466,\n",
       "         0.02101027, 0.01619141, 0.01843138, 0.01447549, 0.01799729,\n",
       "         0.01000477, 0.01128765, 0.01501784, 0.02688009, 0.01152115,\n",
       "         0.01274211, 0.01509973, 0.01695388, 0.0182743 , 0.01236727,\n",
       "         0.01023194, 0.02568318, 0.01014177, 0.01641204, 0.01897841]]),\n",
       " 'metric_means': array([0.01843556, 0.01964678, 0.01396635, 0.01722793, 0.01752477,\n",
       "        0.01657342, 0.0168236 , 0.01954401, 0.02801757, 0.01606936]),\n",
       " 'metric_stds': array([0.00635193, 0.00620765, 0.00328292, 0.00485365, 0.00500137,\n",
       "        0.00511628, 0.00435302, 0.00632865, 0.01197676, 0.00416925])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SWDMetric.Test_np()\n",
    "SWDMetric.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting FN metric calculation...\n",
      "niter = 10\n",
      "batch_size = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 10/10 [00:00<00:00, 963.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running numpy FN calculation...\n",
      "Two-sample test calculation completed in 0.013392308261245489 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric_list': array([0.09314386, 0.08808853, 0.08374531, 0.06171508, 0.07140414,\n",
       "        0.0578714 , 0.08959873, 0.07455605, 0.06733407, 0.10303932])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FNMetric.Test_np()\n",
    "FNMetric.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting LR metric calculation...\n",
      "niter = 10\n",
      "batch_size = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 10/10 [00:00<00:00, 184.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running numpy LR calculation...\n",
      "Two-sample test calculation completed in 0.05648522824048996 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logprob_ref_ref_sum_list': array([-85207.04463663, -84928.14432822, -85286.16133344, -85317.6601523 ,\n",
       "        -85273.44601716, -85085.06617104, -84947.47842401, -85105.46653338,\n",
       "        -85165.21628397, -84980.6448229 ]),\n",
       " 'logprob_ref_alt_sum_list': array([-85230.05318161, -85358.90085422, -85116.1892755 , -84888.56116002,\n",
       "        -84957.02010801, -85154.46546787, -84918.39184454, -84837.27745845,\n",
       "        -84832.09334904, -85123.40946067]),\n",
       " 'logprob_alt_alt_sum_list': array([-85226.31115976, -85360.8465921 , -85116.4740982 , -84885.14995549,\n",
       "        -84955.15271989, -85153.35752981, -84918.12438841, -84836.29354815,\n",
       "        -84830.83869823, -85122.95465738]),\n",
       " 'lik_ratio_list': array([ 7.48404369, -3.89147574, -0.5696454 ,  6.82240907,  3.73477624,\n",
       "         2.21587611,  0.53491226,  1.96782059,  2.50930161,  0.90960658]),\n",
       " 'lik_ratio_norm_list': array([ 0.07484044, -0.03891476, -0.00569645,  0.06822409,  0.03734776,\n",
       "         0.02215876,  0.00534912,  0.01967821,  0.02509302,  0.00909607])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRMetric.Test_np()\n",
    "LRMetric.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute tests TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting KS tests calculation...\n",
      "Running TF KS tests...\n",
      "niter = 10\n",
      "batch_size = 100000\n",
      "The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.\n",
      "The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.\n",
      "nchunks = 5\n",
      "Iterating from 0 to 2 out of 10 .\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "Iterating from 2 to 4 out of 10 .\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "Iterating from 4 to 6 out of 10 .\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "Iterating from 6 to 8 out of 10 .\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "Iterating from 8 to 10 out of 10 .\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f830c5aa790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "KS tests calculation completed in 74.53396456921473 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'statistic_lists': array([[0.00414002, 0.00749999, 0.00387001, ..., 0.00506002, 0.00532001,\n",
       "         0.00288999],\n",
       "        [0.00440001, 0.00398999, 0.00422001, ..., 0.00352   , 0.00501001,\n",
       "         0.00316998],\n",
       "        [0.00479001, 0.00729001, 0.00357997, ..., 0.00860003, 0.00418001,\n",
       "         0.00394002],\n",
       "        ...,\n",
       "        [0.00442004, 0.00839999, 0.00444999, ..., 0.00404999, 0.00858   ,\n",
       "         0.00521004],\n",
       "        [0.00327   , 0.00340003, 0.00558999, ..., 0.00737   , 0.00309001,\n",
       "         0.00251001],\n",
       "        [0.00344002, 0.00334001, 0.00182998, ..., 0.00604001, 0.00269002,\n",
       "         0.00266999]]),\n",
       " 'statistic_means': array([0.00424853, 0.00430084, 0.00429194, 0.00417012, 0.00428764,\n",
       "        0.00420503, 0.00429772, 0.00417215, 0.00420619, 0.00419778]),\n",
       " 'statistic_stds': array([0.001354  , 0.00135258, 0.00136741, 0.00128656, 0.00133131,\n",
       "        0.0013049 , 0.0013003 , 0.00131446, 0.0012754 , 0.00132053]),\n",
       " 'pvalue_lists': array([[0.35819006, 0.00721323, 0.44228828, ..., 0.15447986, 0.11797166,\n",
       "         0.79784   ],\n",
       "        [0.28768957, 0.40360415, 0.33537877, ..., 0.56527436, 0.16244614,\n",
       "         0.69649029],\n",
       "        [0.2014336 , 0.00984025, 0.54331839, ..., 0.00122738, 0.34666073,\n",
       "         0.4194712 ],\n",
       "        ...,\n",
       "        [0.28269631, 0.00172448, 0.27534497, ..., 0.38503903, 0.00127029,\n",
       "         0.13244379],\n",
       "        [0.65887237, 0.60990858, 0.08788389, ..., 0.00875139, 0.72624838,\n",
       "         0.91106915],\n",
       "        [0.59494275, 0.63247544, 0.99613369, ..., 0.05207664, 0.86228228,\n",
       "         0.86819357]]),\n",
       " 'pvalue_means': array([0.42431612, 0.40878053, 0.4146255 , 0.43620645, 0.41106281,\n",
       "        0.42990376, 0.40530692, 0.43911968, 0.42522563, 0.43271914]),\n",
       " 'pvalue_stds': array([0.29237047, 0.29178544, 0.29472024, 0.29331638, 0.29093562,\n",
       "        0.29291852, 0.28251521, 0.29882006, 0.29030645, 0.29348459])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KSTest.Test_tf(max_vectorize=2500)\n",
    "KSTest.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting SKS metric calculation...\n",
      "Running TF SKS calculation...\n",
      "niter = 10\n",
      "batch_size = 10000\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "SKS metric calculation completed in 24.381365718785673 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric_lists': array([[0.01049995, 0.01270002, 0.00939998, 0.01050001, 0.00920004,\n",
       "         0.0138    , 0.00830001, 0.0142    , 0.01390004, 0.01100001,\n",
       "         0.01010001, 0.00860006, 0.01699996, 0.01249999, 0.01030001,\n",
       "         0.01359999, 0.02020001, 0.014     , 0.01070002, 0.01520002,\n",
       "         0.01530004, 0.0187    , 0.01409996, 0.01090002, 0.01180002,\n",
       "         0.0093    , 0.00980002, 0.00920001, 0.01809999, 0.01279998,\n",
       "         0.0102    , 0.0124    , 0.01820001, 0.01320004, 0.0165    ,\n",
       "         0.0185    , 0.0126    , 0.0076    , 0.00999999, 0.01490003,\n",
       "         0.01350001, 0.0165    , 0.01180001, 0.0176    , 0.00779998,\n",
       "         0.01909998, 0.01310003, 0.00999999, 0.01700002, 0.01000002,\n",
       "         0.01320004, 0.01160002, 0.01299995, 0.01259999, 0.02060002,\n",
       "         0.02130002, 0.01389998, 0.01609999, 0.00919998, 0.0151    ,\n",
       "         0.01370001, 0.01700002, 0.0116    , 0.01159999, 0.01170003,\n",
       "         0.00910002, 0.0151    , 0.01899999, 0.0106    , 0.01130003,\n",
       "         0.01300001, 0.01100001, 0.0131    , 0.01239999, 0.01340002,\n",
       "         0.00690001, 0.0097    , 0.016     , 0.00850001, 0.01539999,\n",
       "         0.00870001, 0.01129997, 0.01610005, 0.0073    , 0.01229998,\n",
       "         0.00750002, 0.01160002, 0.00700003, 0.01159999, 0.00919999,\n",
       "         0.01090002, 0.01550001, 0.014     , 0.01259995, 0.01569998,\n",
       "         0.01090002, 0.01770002, 0.01320004, 0.01160002, 0.0104    ],\n",
       "        [0.01179999, 0.01750001, 0.0104    , 0.00929999, 0.01270002,\n",
       "         0.0077    , 0.0133    , 0.01289999, 0.01420003, 0.01190001,\n",
       "         0.0187    , 0.00709999, 0.00929999, 0.01139998, 0.01289999,\n",
       "         0.01550001, 0.01410002, 0.00930001, 0.0086    , 0.01720002,\n",
       "         0.0096    , 0.01800001, 0.01179999, 0.0088    , 0.00890002,\n",
       "         0.01390001, 0.00919998, 0.01300001, 0.01480001, 0.014     ,\n",
       "         0.009     , 0.01530004, 0.0096    , 0.0126    , 0.01369999,\n",
       "         0.00910001, 0.01210001, 0.0122    , 0.01250005, 0.00849998,\n",
       "         0.0257    , 0.0092    , 0.01480001, 0.01549999, 0.0138    ,\n",
       "         0.0098    , 0.0115    , 0.00920001, 0.01450002, 0.0098    ,\n",
       "         0.00910002, 0.0097    , 0.0115    , 0.01060003, 0.01640004,\n",
       "         0.01190001, 0.01189998, 0.01710004, 0.0169    , 0.00880003,\n",
       "         0.01460001, 0.02219999, 0.00710005, 0.01239997, 0.0106    ,\n",
       "         0.01190001, 0.0068    , 0.01180005, 0.0142    , 0.009     ,\n",
       "         0.01249999, 0.0088    , 0.00920001, 0.01340002, 0.01160002,\n",
       "         0.01440001, 0.01140001, 0.0142    , 0.01109999, 0.0169    ,\n",
       "         0.0106    , 0.0079    , 0.01190001, 0.01049998, 0.0133    ,\n",
       "         0.01179999, 0.01179999, 0.01269996, 0.00850001, 0.0097    ,\n",
       "         0.0183    , 0.01340002, 0.01190001, 0.00940001, 0.01019996,\n",
       "         0.01539999, 0.01120001, 0.0088    , 0.01600003, 0.01519999],\n",
       "        [0.00620002, 0.01430005, 0.01380002, 0.009     , 0.01170003,\n",
       "         0.00870001, 0.01010001, 0.0075    , 0.01010001, 0.01089999,\n",
       "         0.00860006, 0.0126    , 0.0096    , 0.00889999, 0.00590003,\n",
       "         0.0097    , 0.01090001, 0.0149    , 0.01060003, 0.0113    ,\n",
       "         0.0068    , 0.009     , 0.00779998, 0.00920001, 0.01169997,\n",
       "         0.0063    , 0.01409996, 0.0147    , 0.01109999, 0.01520002,\n",
       "         0.00889999, 0.01089999, 0.01280001, 0.01199996, 0.0108    ,\n",
       "         0.0117    , 0.01160002, 0.0088    , 0.01670003, 0.01350001,\n",
       "         0.00840002, 0.01250002, 0.0103    , 0.0077    , 0.00660002,\n",
       "         0.01060003, 0.00870001, 0.01120001, 0.00840002, 0.00929999,\n",
       "         0.00959998, 0.01370001, 0.01569998, 0.00710002, 0.00580001,\n",
       "         0.00980002, 0.01050001, 0.00800002, 0.01249999, 0.00839999,\n",
       "         0.00669998, 0.00669998, 0.01359999, 0.00940001, 0.01100001,\n",
       "         0.00749999, 0.0059    , 0.01120001, 0.01249999, 0.0116    ,\n",
       "         0.01589996, 0.014     , 0.01179999, 0.00950003, 0.01030001,\n",
       "         0.00750002, 0.00860001, 0.00810003, 0.01170003, 0.00929999,\n",
       "         0.01460004, 0.0095    , 0.01099999, 0.01370001, 0.01070005,\n",
       "         0.01010001, 0.01199999, 0.0073    , 0.0095    , 0.01050001,\n",
       "         0.00830001, 0.00630003, 0.0147    , 0.00840002, 0.01119995,\n",
       "         0.00760001, 0.00910002, 0.00919998, 0.0072    , 0.01289999],\n",
       "        [0.009     , 0.01669997, 0.00909996, 0.01860002, 0.01049998,\n",
       "         0.01020002, 0.01639998, 0.0099    , 0.013     , 0.00770003,\n",
       "         0.0097    , 0.00730002, 0.0106    , 0.01520002, 0.01350003,\n",
       "         0.00730002, 0.01739997, 0.0106    , 0.00940001, 0.0124    ,\n",
       "         0.01339999, 0.0079    , 0.01320004, 0.01090002, 0.01060003,\n",
       "         0.01230001, 0.014     , 0.01339999, 0.01290001, 0.0108    ,\n",
       "         0.0077    , 0.01120001, 0.01660001, 0.01159999, 0.01380002,\n",
       "         0.0142    , 0.01280004, 0.00879999, 0.01120001, 0.00960001,\n",
       "         0.01310003, 0.00730002, 0.00959998, 0.0183    , 0.00950003,\n",
       "         0.00999999, 0.01569998, 0.01259995, 0.01299995, 0.00940001,\n",
       "         0.009     , 0.01349998, 0.00939998, 0.01270002, 0.00780001,\n",
       "         0.01350001, 0.00639999, 0.00980002, 0.01199996, 0.01230001,\n",
       "         0.0169    , 0.0108    , 0.01980001, 0.00930001, 0.01230001,\n",
       "         0.00840002, 0.01300001, 0.014     , 0.01699999, 0.01390001,\n",
       "         0.00860001, 0.01270002, 0.00889999, 0.0124    , 0.00869998,\n",
       "         0.01130003, 0.00940001, 0.00930001, 0.01070002, 0.01190001,\n",
       "         0.01160002, 0.01109999, 0.0147    , 0.0078    , 0.01130001,\n",
       "         0.01010001, 0.01109999, 0.01660001, 0.00920001, 0.00760001,\n",
       "         0.00779998, 0.00729999, 0.0205    , 0.01270002, 0.0072    ,\n",
       "         0.0097    , 0.01109999, 0.0108    , 0.01179999, 0.01060003],\n",
       "        [0.0124    , 0.01270002, 0.00800002, 0.01500002, 0.01160002,\n",
       "         0.01269999, 0.01159999, 0.0097    , 0.0106    , 0.01479998,\n",
       "         0.01220003, 0.01390004, 0.01230001, 0.01450002, 0.0104    ,\n",
       "         0.0104    , 0.00950003, 0.02029997, 0.01990002, 0.0095    ,\n",
       "         0.01300001, 0.01440001, 0.01019999, 0.01450001, 0.00950003,\n",
       "         0.01359999, 0.01819998, 0.00839999, 0.01020001, 0.01209998,\n",
       "         0.01820004, 0.01020002, 0.0151    , 0.01289999, 0.01590002,\n",
       "         0.0108    , 0.01820001, 0.01320001, 0.01630002, 0.01340002,\n",
       "         0.01789999, 0.01059999, 0.00839996, 0.0151    , 0.0064    ,\n",
       "         0.01130003, 0.01160002, 0.00780004, 0.00830001, 0.01090002,\n",
       "         0.01560003, 0.01419997, 0.01680002, 0.01239997, 0.0122    ,\n",
       "         0.0077    , 0.0108    , 0.01359999, 0.01140001, 0.00710005,\n",
       "         0.0077    , 0.01019999, 0.0107    , 0.0142    , 0.02740002,\n",
       "         0.01050001, 0.0151    , 0.00889999, 0.0089    , 0.00810003,\n",
       "         0.01109999, 0.01350003, 0.00870001, 0.01429999, 0.01700002,\n",
       "         0.01730001, 0.00740004, 0.01339999, 0.0095    , 0.01460001,\n",
       "         0.01020002, 0.01430002, 0.00810003, 0.0106    , 0.01350001,\n",
       "         0.01019999, 0.01199996, 0.02079999, 0.01360002, 0.00989997,\n",
       "         0.01970002, 0.01110001, 0.01189998, 0.01740003, 0.01249999,\n",
       "         0.01639998, 0.01409999, 0.00840002, 0.01729995, 0.01499999],\n",
       "        [0.00849998, 0.01140001, 0.01889998, 0.00870001, 0.01069999,\n",
       "         0.00980002, 0.0081    , 0.0122    , 0.01820004, 0.01109999,\n",
       "         0.01350003, 0.00960001, 0.0099    , 0.01420003, 0.01020002,\n",
       "         0.0097    , 0.00940001, 0.01339999, 0.009     , 0.0086    ,\n",
       "         0.01109999, 0.0133    , 0.00690001, 0.01130003, 0.00880001,\n",
       "         0.00810003, 0.00650001, 0.01249999, 0.01010001, 0.01019996,\n",
       "         0.009     , 0.0174    , 0.01430002, 0.01070002, 0.00920004,\n",
       "         0.0113    , 0.0174    , 0.01520002, 0.01880002, 0.0124    ,\n",
       "         0.00850004, 0.0113    , 0.0108    , 0.0095    , 0.00840002,\n",
       "         0.01570001, 0.01000005, 0.01249999, 0.00910002, 0.01489997,\n",
       "         0.01090002, 0.0099    , 0.0142    , 0.01499999, 0.00950003,\n",
       "         0.0126    , 0.007     , 0.01209998, 0.01180002, 0.0068    ,\n",
       "         0.01230001, 0.00680003, 0.0068    , 0.0187    , 0.0122    ,\n",
       "         0.01240003, 0.01320001, 0.01560003, 0.01729999, 0.007     ,\n",
       "         0.0097    , 0.0097    , 0.01190001, 0.0115    , 0.01000001,\n",
       "         0.01050001, 0.01180005, 0.01019999, 0.00920001, 0.01109999,\n",
       "         0.009     , 0.01179999, 0.00870001, 0.01209998, 0.0201    ,\n",
       "         0.01340002, 0.00780001, 0.00849998, 0.0126    , 0.01560003,\n",
       "         0.0165    , 0.0133    , 0.01090002, 0.02110001, 0.01339999,\n",
       "         0.01289999, 0.0088    , 0.0156    , 0.0149    , 0.01560003],\n",
       "        [0.0074    , 0.01170003, 0.0112    , 0.01340002, 0.0133    ,\n",
       "         0.01500002, 0.01190001, 0.01250005, 0.01570004, 0.00690001,\n",
       "         0.01500002, 0.01180005, 0.00920004, 0.01539999, 0.01090001,\n",
       "         0.00839999, 0.0165    , 0.01679999, 0.0079    , 0.0089    ,\n",
       "         0.01259999, 0.00709999, 0.00840002, 0.01259997, 0.01129997,\n",
       "         0.01279999, 0.01440001, 0.00809997, 0.01310003, 0.01460001,\n",
       "         0.0108    , 0.0108    , 0.00960001, 0.0093    , 0.00950003,\n",
       "         0.01160002, 0.0099    , 0.01200002, 0.01380002, 0.01120001,\n",
       "         0.0126    , 0.0082    , 0.00929999, 0.01789999, 0.01179999,\n",
       "         0.0054    , 0.01100004, 0.01189999, 0.01590002, 0.00999999,\n",
       "         0.01750004, 0.0115    , 0.0122    , 0.00820002, 0.00980002,\n",
       "         0.01550001, 0.01570004, 0.01110001, 0.01490003, 0.01169997,\n",
       "         0.01370001, 0.00890002, 0.009     , 0.01199999, 0.01320001,\n",
       "         0.00890005, 0.01359999, 0.00969999, 0.01370001, 0.01190001,\n",
       "         0.0147    , 0.00860003, 0.01149999, 0.00920001, 0.01009995,\n",
       "         0.00730002, 0.01000002, 0.01249999, 0.01360002, 0.0133    ,\n",
       "         0.01109999, 0.0115    , 0.01110002, 0.00820005, 0.01010001,\n",
       "         0.01160002, 0.00980002, 0.00840002, 0.01269996, 0.0079    ,\n",
       "         0.0099    , 0.00800002, 0.0072    , 0.01040001, 0.01320001,\n",
       "         0.0134    , 0.00740001, 0.01749998, 0.0124    , 0.00959998],\n",
       "        [0.01750001, 0.01010001, 0.01450001, 0.01060003, 0.01450002,\n",
       "         0.00780004, 0.01179999, 0.00960001, 0.00930001, 0.01280001,\n",
       "         0.0187    , 0.0187    , 0.0079    , 0.00920001, 0.00999999,\n",
       "         0.01030004, 0.0124    , 0.0229    , 0.01279998, 0.01730001,\n",
       "         0.01280004, 0.01279998, 0.01390001, 0.01280004, 0.0149    ,\n",
       "         0.01820004, 0.00909999, 0.00830001, 0.00739998, 0.01170003,\n",
       "         0.0081    , 0.0117    , 0.0219    , 0.01459998, 0.0079    ,\n",
       "         0.0169    , 0.01130003, 0.01890001, 0.01520002, 0.01320001,\n",
       "         0.00880003, 0.01270002, 0.00980002, 0.0086    , 0.01210001,\n",
       "         0.0121    , 0.00940001, 0.01350001, 0.01660001, 0.02000001,\n",
       "         0.01090002, 0.01089996, 0.01859999, 0.01210004, 0.01050001,\n",
       "         0.01889998, 0.01179999, 0.01899999, 0.01189998, 0.01029998,\n",
       "         0.01090002, 0.01460004, 0.014     , 0.00850004, 0.01559997,\n",
       "         0.00819999, 0.01640001, 0.0158    , 0.00870001, 0.0096    ,\n",
       "         0.0149    , 0.01320004, 0.01019996, 0.01719999, 0.00940001,\n",
       "         0.01530001, 0.01100004, 0.014     , 0.01089999, 0.00730002,\n",
       "         0.00919998, 0.01770002, 0.01440001, 0.01269999, 0.01459998,\n",
       "         0.01320004, 0.01660001, 0.01730001, 0.01570004, 0.01030001,\n",
       "         0.0098    , 0.014     , 0.00920001, 0.0147    , 0.0187    ,\n",
       "         0.009     , 0.01770002, 0.01380001, 0.01440001, 0.01019999],\n",
       "        [0.00669998, 0.01440001, 0.01890001, 0.0194    , 0.02450001,\n",
       "         0.01369999, 0.01190001, 0.0201    , 0.01700002, 0.01319999,\n",
       "         0.014     , 0.0108    , 0.01110001, 0.02420002, 0.0099    ,\n",
       "         0.01720002, 0.01930001, 0.01210001, 0.0086    , 0.0123    ,\n",
       "         0.0126    , 0.01199999, 0.01499999, 0.01820004, 0.0194    ,\n",
       "         0.00959998, 0.0134    , 0.00850004, 0.02129999, 0.01630002,\n",
       "         0.01700002, 0.00759999, 0.01179999, 0.0097    , 0.01299995,\n",
       "         0.0203    , 0.01859999, 0.0183    , 0.01910001, 0.02280003,\n",
       "         0.01989999, 0.01519999, 0.01339999, 0.01589999, 0.0122    ,\n",
       "         0.0116    , 0.01280001, 0.016     , 0.00749999, 0.02530003,\n",
       "         0.01239997, 0.02260005, 0.009     , 0.01660001, 0.02579999,\n",
       "         0.00820002, 0.0223    , 0.01430002, 0.02250004, 0.01160002,\n",
       "         0.00830001, 0.0104    , 0.0289    , 0.00800002, 0.01930001,\n",
       "         0.01339999, 0.01929998, 0.02200001, 0.01640004, 0.01840001,\n",
       "         0.0284    , 0.0149    , 0.017     , 0.01730001, 0.01819998,\n",
       "         0.03359997, 0.02780002, 0.0151    , 0.02290002, 0.014     ,\n",
       "         0.02110004, 0.0104    , 0.02169997, 0.0061    , 0.01600003,\n",
       "         0.01339999, 0.02160001, 0.01209998, 0.02040002, 0.0165    ,\n",
       "         0.01550001, 0.01549995, 0.0134    , 0.01159999, 0.01709998,\n",
       "         0.02050003, 0.0284    , 0.0255    , 0.0122    , 0.0074    ],\n",
       "        [0.01599997, 0.01280004, 0.0147    , 0.01289999, 0.01049998,\n",
       "         0.01280001, 0.00989997, 0.01040003, 0.007     , 0.01030001,\n",
       "         0.00940001, 0.0107    , 0.0099    , 0.01210001, 0.02160001,\n",
       "         0.01120001, 0.01060003, 0.00920001, 0.01440004, 0.01030001,\n",
       "         0.01359999, 0.00910002, 0.01359999, 0.01030001, 0.01750001,\n",
       "         0.00840002, 0.0104    , 0.0106    , 0.01539999, 0.01099998,\n",
       "         0.01340002, 0.0086    , 0.0069    , 0.01270002, 0.00840002,\n",
       "         0.00850004, 0.01480001, 0.0122    , 0.01090002, 0.0113    ,\n",
       "         0.00799999, 0.00770003, 0.01109999, 0.013     , 0.00910002,\n",
       "         0.00880003, 0.01359999, 0.01899999, 0.00780001, 0.01010001,\n",
       "         0.0115    , 0.0057    , 0.01140001, 0.00779998, 0.0068    ,\n",
       "         0.01600002, 0.01270002, 0.01070005, 0.01190001, 0.01050001,\n",
       "         0.00740001, 0.00989999, 0.00709999, 0.00739998, 0.01069999,\n",
       "         0.01090001, 0.00659999, 0.01420003, 0.01160002, 0.01090002,\n",
       "         0.0079    , 0.01460001, 0.0104    , 0.00929999, 0.01139998,\n",
       "         0.01209998, 0.0122    , 0.01710001, 0.0122    , 0.00930001,\n",
       "         0.0194    , 0.00940001, 0.01199999, 0.00670001, 0.00920001,\n",
       "         0.0106    , 0.01390001, 0.01410002, 0.00909999, 0.0097    ,\n",
       "         0.0151    , 0.01289999, 0.01279998, 0.00929999, 0.00999999,\n",
       "         0.0113    , 0.009     , 0.01060003, 0.00799996, 0.01539999]]),\n",
       " 'metric_means': array([0.01278001, 0.012227  , 0.010303  , 0.011562  , 0.012659  ,\n",
       "        0.01170601, 0.01142201, 0.01297701, 0.016189  , 0.011192  ]),\n",
       " 'metric_stds': array([0.00328046, 0.00324148, 0.00255927, 0.00300162, 0.00357312,\n",
       "        0.00321829, 0.00269064, 0.00356387, 0.00563154, 0.00294057])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SKSTest.Test_tf(nslices = 100)\n",
    "SKSTest.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiKS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting MultiKS tests calculation...\n",
      "Running TF MultiKS tests...\n",
      "niter = 10\n",
      "batch_size = 10000\n",
      "MultiKS tests calculation completed in 1.984137796331197 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric_list': array([0.01609999, 0.01560001, 0.0156    , 0.0156    , 0.0165    ,\n",
       "        0.01799998, 0.01270001, 0.01459999, 0.02699998, 0.0124    ])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiKSTest.Test_tf()\n",
    "MultiKSTest.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWD Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting SWD metric calculation...\n",
      "Running TF SWD calculation...\n",
      "niter = 10\n",
      "batch_size = 10000\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "WARNING:tensorflow:Using a while_loop for converting TopKV2\n",
      "SWD metric calculation completed in 2.3067483538761735 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric_lists': array([[0.0157901 , 0.01624843, 0.02081172, 0.01628134, 0.02122319,\n",
       "         0.01666596, 0.01359905, 0.02699844, 0.01369063, 0.02369807,\n",
       "         0.0126657 , 0.01762032, 0.03338795, 0.01973412, 0.02282575,\n",
       "         0.01445777, 0.023957  , 0.01064548, 0.02998537, 0.01742752,\n",
       "         0.01880943, 0.01690881, 0.01123532, 0.02461224, 0.01492176,\n",
       "         0.0158887 , 0.01798689, 0.0184254 , 0.01109558, 0.01649103,\n",
       "         0.02015282, 0.02355163, 0.01014153, 0.02888699, 0.02242315,\n",
       "         0.0168857 , 0.02195021, 0.01518754, 0.02492058, 0.01701782,\n",
       "         0.02357967, 0.02526429, 0.01539084, 0.01842299, 0.01696122,\n",
       "         0.02246575, 0.02392423, 0.02218166, 0.02378514, 0.01640921,\n",
       "         0.03245075, 0.01550098, 0.01261229, 0.01135541, 0.01370972,\n",
       "         0.0133804 , 0.01938696, 0.01507822, 0.02549362, 0.01431948,\n",
       "         0.01605022, 0.01601575, 0.02138653, 0.0207938 , 0.02015061,\n",
       "         0.03102089, 0.0163235 , 0.02107141, 0.01308115, 0.01957204,\n",
       "         0.01729629, 0.01503223, 0.02015207, 0.00856798, 0.02676192,\n",
       "         0.01139383, 0.01569007, 0.02110319, 0.0125093 , 0.01464651,\n",
       "         0.02851473, 0.01298596, 0.0170507 , 0.01854599, 0.02905315,\n",
       "         0.02165291, 0.0177082 , 0.01533416, 0.03165269, 0.01575063,\n",
       "         0.01759409, 0.01651523, 0.01113755, 0.01774687, 0.00866727,\n",
       "         0.01454722, 0.019615  , 0.0163719 , 0.01361205, 0.02540021],\n",
       "        [0.01885083, 0.01630005, 0.02696305, 0.0181979 , 0.01509195,\n",
       "         0.01830063, 0.02924589, 0.01258643, 0.01780546, 0.01955136,\n",
       "         0.02135121, 0.02858631, 0.0244114 , 0.01124329, 0.01349221,\n",
       "         0.01428395, 0.02735534, 0.02768753, 0.02563616, 0.02183113,\n",
       "         0.01123876, 0.02208439, 0.01776886, 0.01254841, 0.01853441,\n",
       "         0.02604956, 0.02125451, 0.01667841, 0.01752398, 0.02418425,\n",
       "         0.02168468, 0.018497  , 0.01056376, 0.02146233, 0.01590333,\n",
       "         0.01873697, 0.01999294, 0.01034762, 0.02131789, 0.0247842 ,\n",
       "         0.01517505, 0.02530272, 0.01356795, 0.01978042, 0.01268675,\n",
       "         0.01503321, 0.02421106, 0.02041296, 0.01238547, 0.01680185,\n",
       "         0.02343959, 0.01947401, 0.01156031, 0.02062262, 0.02517045,\n",
       "         0.01897302, 0.01347838, 0.01476156, 0.02411269, 0.01341458,\n",
       "         0.01463591, 0.019599  , 0.02038125, 0.03388216, 0.01491753,\n",
       "         0.01507058, 0.02698998, 0.03207748, 0.01345213, 0.03302072,\n",
       "         0.01770284, 0.01842564, 0.02591657, 0.02076261, 0.02747877,\n",
       "         0.01900162, 0.01851587, 0.01484977, 0.01660773, 0.02218541,\n",
       "         0.01227432, 0.0241589 , 0.02349604, 0.02104846, 0.01296699,\n",
       "         0.0209614 , 0.01959405, 0.02996158, 0.01217647, 0.02003535,\n",
       "         0.01526024, 0.01544908, 0.01569636, 0.01735875, 0.01892959,\n",
       "         0.01506936, 0.01454831, 0.02812858, 0.01349175, 0.0127518 ],\n",
       "        [0.01434798, 0.0164702 , 0.02225126, 0.02477699, 0.01473057,\n",
       "         0.01507482, 0.01392005, 0.01023245, 0.01231148, 0.00997728,\n",
       "         0.01082695, 0.01684059, 0.01424794, 0.01112333, 0.01785004,\n",
       "         0.01387384, 0.01833258, 0.01630572, 0.01362131, 0.01403565,\n",
       "         0.01359881, 0.01888778, 0.00975247, 0.02020438, 0.01291463,\n",
       "         0.01018285, 0.01463048, 0.01188955, 0.009548  , 0.0129834 ,\n",
       "         0.01327489, 0.0128717 , 0.00933341, 0.01572712, 0.0156116 ,\n",
       "         0.01425917, 0.01294183, 0.01319185, 0.01380004, 0.01143367,\n",
       "         0.01260398, 0.01451489, 0.0118236 , 0.01413155, 0.01918814,\n",
       "         0.01599944, 0.0110338 , 0.00784591, 0.00880143, 0.01878261,\n",
       "         0.00942034, 0.01159524, 0.01978025, 0.01180197, 0.01401622,\n",
       "         0.022066  , 0.01695676, 0.01681059, 0.0189326 , 0.01662542,\n",
       "         0.01087368, 0.01373573, 0.01474021, 0.00947791, 0.01500868,\n",
       "         0.01572825, 0.01865548, 0.02001389, 0.01068534, 0.01221645,\n",
       "         0.01042592, 0.01289919, 0.01415856, 0.01433554, 0.0167064 ,\n",
       "         0.00972705, 0.01348545, 0.01176908, 0.01669951, 0.0161818 ,\n",
       "         0.0115171 , 0.02101459, 0.01676559, 0.01483261, 0.01052564,\n",
       "         0.01766097, 0.01056647, 0.01564905, 0.01546637, 0.01360739,\n",
       "         0.01612524, 0.0086278 , 0.01512681, 0.01258199, 0.01416079,\n",
       "         0.00821271, 0.0128533 , 0.00741821, 0.00942357, 0.01317946],\n",
       "        [0.01504624, 0.02055165, 0.02041879, 0.01361458, 0.01401941,\n",
       "         0.01470222, 0.0171166 , 0.00945471, 0.02517761, 0.02015444,\n",
       "         0.02222296, 0.0190984 , 0.02834941, 0.00770226, 0.02140936,\n",
       "         0.01286795, 0.01702559, 0.01841938, 0.0284305 , 0.01234938,\n",
       "         0.01429271, 0.01027876, 0.01880999, 0.02831335, 0.01455294,\n",
       "         0.01905337, 0.02589813, 0.02004979, 0.01755303, 0.01613419,\n",
       "         0.015314  , 0.02561083, 0.02511889, 0.01211538, 0.0161944 ,\n",
       "         0.00906637, 0.02220335, 0.01912247, 0.01430399, 0.0151328 ,\n",
       "         0.01711808, 0.0101115 , 0.01394347, 0.02381876, 0.02701305,\n",
       "         0.01630673, 0.01337219, 0.01179347, 0.01743089, 0.01790984,\n",
       "         0.0148471 , 0.01647039, 0.01280939, 0.01263309, 0.0175597 ,\n",
       "         0.02313967, 0.01476454, 0.01724938, 0.01327364, 0.01406988,\n",
       "         0.0182542 , 0.01122631, 0.01771832, 0.02775455, 0.02104196,\n",
       "         0.01977693, 0.01403741, 0.01674528, 0.01005536, 0.02075315,\n",
       "         0.02644533, 0.01372302, 0.01657137, 0.01906976, 0.01316941,\n",
       "         0.02088478, 0.02258242, 0.02038859, 0.01396003, 0.01006377,\n",
       "         0.02976937, 0.01291363, 0.02334791, 0.01645446, 0.01770488,\n",
       "         0.02014392, 0.01763625, 0.01783134, 0.01643605, 0.01229844,\n",
       "         0.01593884, 0.01281022, 0.02087561, 0.01244412, 0.01227653,\n",
       "         0.01780004, 0.019652  , 0.02484926, 0.02487837, 0.01120206],\n",
       "        [0.0220827 , 0.02480426, 0.01975727, 0.02058561, 0.02346801,\n",
       "         0.0234048 , 0.00987193, 0.01995414, 0.01053057, 0.01955452,\n",
       "         0.02630502, 0.02034404, 0.01649362, 0.01669589, 0.01945388,\n",
       "         0.02127306, 0.00960912, 0.02464132, 0.01999648, 0.01687776,\n",
       "         0.01794426, 0.01624659, 0.01651742, 0.02443327, 0.01342016,\n",
       "         0.02985313, 0.02054824, 0.01125618, 0.01295238, 0.02388192,\n",
       "         0.02332829, 0.01636185, 0.03261686, 0.01395857, 0.01826219,\n",
       "         0.0274833 , 0.0292474 , 0.01868146, 0.01208517, 0.02447955,\n",
       "         0.00974535, 0.01723466, 0.02494328, 0.01548744, 0.02083742,\n",
       "         0.00799344, 0.01666369, 0.02122022, 0.0180247 , 0.02221572,\n",
       "         0.01608712, 0.02197473, 0.02027553, 0.01161553, 0.01664253,\n",
       "         0.02019329, 0.01561166, 0.01876584, 0.01786664, 0.0157883 ,\n",
       "         0.01981532, 0.01736123, 0.01878032, 0.02817361, 0.01539548,\n",
       "         0.01743149, 0.015458  , 0.0226423 , 0.01176345, 0.02218707,\n",
       "         0.01722823, 0.02287522, 0.02237951, 0.01775667, 0.01564931,\n",
       "         0.01878024, 0.01214212, 0.01779761, 0.01651571, 0.01697922,\n",
       "         0.02520152, 0.01184632, 0.01903593, 0.01416903, 0.00992959,\n",
       "         0.0093246 , 0.00910267, 0.02680437, 0.02321254, 0.02771098,\n",
       "         0.02124233, 0.00776365, 0.01865733, 0.01611173, 0.02699342,\n",
       "         0.01879309, 0.02745769, 0.01195832, 0.01595033, 0.0184835 ],\n",
       "        [0.01469666, 0.01980422, 0.01749987, 0.01100781, 0.02191971,\n",
       "         0.01755251, 0.01377583, 0.01661573, 0.01767646, 0.01663853,\n",
       "         0.01346756, 0.01637662, 0.01857043, 0.01290111, 0.01753728,\n",
       "         0.01366609, 0.01919293, 0.01443713, 0.01130969, 0.01502049,\n",
       "         0.01711606, 0.01482025, 0.01199428, 0.01320294, 0.00985142,\n",
       "         0.0171436 , 0.02164403, 0.02344894, 0.01389382, 0.01102354,\n",
       "         0.01473834, 0.01616927, 0.01059482, 0.0173372 , 0.01547526,\n",
       "         0.01078454, 0.0239465 , 0.01048301, 0.0145254 , 0.01506682,\n",
       "         0.02407863, 0.01789141, 0.01064111, 0.01442361, 0.01613853,\n",
       "         0.01517241, 0.01626886, 0.01025042, 0.01875763, 0.00957643,\n",
       "         0.01026512, 0.01185608, 0.0165084 , 0.00824906, 0.02116617,\n",
       "         0.01991586, 0.01935384, 0.02163596, 0.01219319, 0.01246494,\n",
       "         0.02600656, 0.01133936, 0.02430773, 0.02320567, 0.02019028,\n",
       "         0.01724228, 0.02252818, 0.0140946 , 0.02850092, 0.01720681,\n",
       "         0.02358968, 0.01279048, 0.0186443 , 0.02701104, 0.00983958,\n",
       "         0.01381202, 0.02569039, 0.01589458, 0.01808263, 0.0132343 ,\n",
       "         0.02410226, 0.02536832, 0.01592   , 0.00887957, 0.01095755,\n",
       "         0.01580604, 0.01558827, 0.0196845 , 0.01006934, 0.01008063,\n",
       "         0.01635281, 0.01558942, 0.01867923, 0.02065788, 0.01116315,\n",
       "         0.00997242, 0.0177627 , 0.01017725, 0.01304112, 0.01061816],\n",
       "        [0.02406212, 0.01211416, 0.02100811, 0.02358022, 0.01709612,\n",
       "         0.01855457, 0.01365842, 0.01927248, 0.00993731, 0.02104355,\n",
       "         0.02482774, 0.01293449, 0.01720349, 0.02061944, 0.02475598,\n",
       "         0.02237704, 0.01628941, 0.01675901, 0.02052253, 0.01815685,\n",
       "         0.0110435 , 0.01635546, 0.01985196, 0.01229885, 0.01459729,\n",
       "         0.01177401, 0.01957341, 0.01520317, 0.02686385, 0.01181864,\n",
       "         0.01359711, 0.01564149, 0.01459518, 0.01017778, 0.01300605,\n",
       "         0.01593887, 0.02637664, 0.00946359, 0.01462595, 0.01541251,\n",
       "         0.01079035, 0.01160386, 0.01385642, 0.01499437, 0.01698146,\n",
       "         0.01097274, 0.01945264, 0.01811793, 0.01021507, 0.01811063,\n",
       "         0.01786199, 0.01754343, 0.01124453, 0.02696917, 0.02482604,\n",
       "         0.01888977, 0.02338316, 0.01904773, 0.02556527, 0.02513737,\n",
       "         0.01767861, 0.01959692, 0.02245712, 0.01226676, 0.01260569,\n",
       "         0.01371129, 0.01504344, 0.02230852, 0.0140777 , 0.01311852,\n",
       "         0.0166305 , 0.01237951, 0.01635501, 0.01814245, 0.02170177,\n",
       "         0.01364535, 0.02697446, 0.00879367, 0.01093537, 0.012477  ,\n",
       "         0.01329158, 0.01893089, 0.00830591, 0.02585274, 0.01604475,\n",
       "         0.01520099, 0.01970283, 0.01119495, 0.02427908, 0.01645345,\n",
       "         0.01238736, 0.01683223, 0.02233698, 0.02226532, 0.01488903,\n",
       "         0.01457869, 0.01326257, 0.01335264, 0.0186143 , 0.0153962 ],\n",
       "        [0.0199418 , 0.01446847, 0.0221438 , 0.01262627, 0.0100338 ,\n",
       "         0.0200966 , 0.01872647, 0.01942413, 0.03608212, 0.02101021,\n",
       "         0.02010544, 0.0183965 , 0.01230808, 0.02200739, 0.02386219,\n",
       "         0.01797093, 0.02610788, 0.01686621, 0.0136377 , 0.00899696,\n",
       "         0.01210991, 0.01798446, 0.00976036, 0.01591742, 0.01390745,\n",
       "         0.02697638, 0.01086853, 0.01512801, 0.0232415 , 0.01687491,\n",
       "         0.0158495 , 0.02002699, 0.0228549 , 0.01959651, 0.01719846,\n",
       "         0.00934761, 0.01825375, 0.03343464, 0.02062636, 0.02474053,\n",
       "         0.01578613, 0.01343979, 0.03071563, 0.02663127, 0.01500323,\n",
       "         0.02697187, 0.02393641, 0.01724505, 0.01540558, 0.01868757,\n",
       "         0.01152378, 0.01187608, 0.01152548, 0.02327139, 0.02097324,\n",
       "         0.02856169, 0.03112001, 0.01488313, 0.02803259, 0.01320058,\n",
       "         0.01877401, 0.02778065, 0.01226972, 0.03152385, 0.01835507,\n",
       "         0.01746852, 0.0181941 , 0.02973122, 0.01160334, 0.01624599,\n",
       "         0.02517242, 0.01392738, 0.01982351, 0.01496075, 0.01619953,\n",
       "         0.02800177, 0.02566581, 0.02851092, 0.02758579, 0.01996461,\n",
       "         0.01734333, 0.01637583, 0.01437835, 0.01977802, 0.01445799,\n",
       "         0.01076302, 0.01947927, 0.01350029, 0.01376534, 0.01305767,\n",
       "         0.01508853, 0.02004608, 0.03511736, 0.01939678, 0.02779615,\n",
       "         0.01066561, 0.01998998, 0.0238957 , 0.03014946, 0.01874038],\n",
       "        [0.05247561, 0.02431825, 0.01418083, 0.04089103, 0.02270255,\n",
       "         0.03309152, 0.03949896, 0.02281429, 0.04735198, 0.0482759 ,\n",
       "         0.01779985, 0.02293072, 0.0233858 , 0.0121796 , 0.02032311,\n",
       "         0.01450643, 0.05281161, 0.02894264, 0.05195057, 0.04423284,\n",
       "         0.01446683, 0.01306533, 0.04173482, 0.04909644, 0.02906616,\n",
       "         0.02184329, 0.02288772, 0.04427409, 0.03543838, 0.03729393,\n",
       "         0.0509515 , 0.0264398 , 0.01948075, 0.01838733, 0.00964311,\n",
       "         0.02587848, 0.016262  , 0.02620755, 0.01631231, 0.03715024,\n",
       "         0.02982784, 0.03808182, 0.02573608, 0.01207872, 0.03421337,\n",
       "         0.01721138, 0.02946313, 0.00935963, 0.04616005, 0.02300259,\n",
       "         0.04401885, 0.04638821, 0.01357286, 0.05480006, 0.0162832 ,\n",
       "         0.02745655, 0.03164587, 0.0485846 , 0.01256985, 0.0203385 ,\n",
       "         0.02036866, 0.02014462, 0.05706429, 0.04818236, 0.03681686,\n",
       "         0.0487261 , 0.03834355, 0.0411098 , 0.01289423, 0.01418379,\n",
       "         0.04289437, 0.01741555, 0.02612547, 0.0297945 , 0.02092372,\n",
       "         0.0189179 , 0.04210022, 0.02650996, 0.03013945, 0.02595539,\n",
       "         0.02958991, 0.01404562, 0.0202808 , 0.01909934, 0.02607408,\n",
       "         0.01344275, 0.02197612, 0.00938022, 0.01924561, 0.01152027,\n",
       "         0.01098696, 0.03305531, 0.027837  , 0.026578  , 0.02530327,\n",
       "         0.01004268, 0.03108594, 0.01560187, 0.03141334, 0.04530516],\n",
       "        [0.02478812, 0.01551359, 0.01131263, 0.01221223, 0.02044369,\n",
       "         0.01850494, 0.01428717, 0.01490666, 0.0180559 , 0.02312732,\n",
       "         0.0272489 , 0.01183823, 0.01352234, 0.01906798, 0.01018794,\n",
       "         0.01883888, 0.02723466, 0.02232089, 0.00984923, 0.0133625 ,\n",
       "         0.02608533, 0.02382938, 0.01193479, 0.01345048, 0.01318776,\n",
       "         0.0186554 , 0.01556264, 0.01328163, 0.01361788, 0.01017074,\n",
       "         0.01198007, 0.01812205, 0.01218611, 0.01096029, 0.02189968,\n",
       "         0.01130921, 0.01332759, 0.01321045, 0.01568379, 0.01406948,\n",
       "         0.01527353, 0.01560511, 0.01364688, 0.01361515, 0.02117329,\n",
       "         0.01204983, 0.01728281, 0.00921911, 0.01306618, 0.01876654,\n",
       "         0.02716421, 0.01150999, 0.02308916, 0.0172771 , 0.02392522,\n",
       "         0.01932344, 0.01263408, 0.0170596 , 0.01239396, 0.01220397,\n",
       "         0.01551786, 0.01388071, 0.01362794, 0.01297122, 0.01208655,\n",
       "         0.01660557, 0.01363558, 0.01403589, 0.01715228, 0.01198976,\n",
       "         0.01280326, 0.01707035, 0.01302905, 0.01494349, 0.01248814,\n",
       "         0.01709865, 0.01019135, 0.01237695, 0.01729052, 0.01963521,\n",
       "         0.01667199, 0.01654757, 0.02272307, 0.02517526, 0.01976121,\n",
       "         0.01084993, 0.01676939, 0.01500982, 0.01779221, 0.01400199,\n",
       "         0.02138294, 0.01864675, 0.0169848 , 0.00888553, 0.01612291,\n",
       "         0.01400747, 0.0157614 , 0.02913079, 0.01967259, 0.01019275]]),\n",
       " 'metric_means': array([0.01864956, 0.01929124, 0.01403759, 0.0175437 , 0.0186531 ,\n",
       "        0.01613416, 0.01692624, 0.01933846, 0.02831812, 0.01609948]),\n",
       " 'metric_stds': array([0.00544936, 0.00542434, 0.0034192 , 0.00498074, 0.00528206,\n",
       "        0.00467502, 0.00474556, 0.00627921, 0.01274466, 0.00455262])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SWDMetric.Test_tf()\n",
    "SWDMetric.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting FN metric calculation...\n",
      "Running TF FN calculation...\n",
      "niter = 100\n",
      "batch_size = 100000\n",
      "The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.\n",
      "The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice\n",
      "FN metric calculation completed in 12.333157137036324 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric_list': array([0.05180409, 0.04011063, 0.04080673, 0.04190643, 0.03794551,\n",
       "        0.04638123, 0.04537611, 0.03983452, 0.04356784, 0.03050198,\n",
       "        0.03707879, 0.04167274, 0.04536643, 0.04429032, 0.05719004,\n",
       "        0.03429299, 0.04411605, 0.04562657, 0.04044119, 0.03594689,\n",
       "        0.04505357, 0.04099417, 0.03741255, 0.04537373, 0.03670273,\n",
       "        0.04564109, 0.03454028, 0.04520403, 0.04232132, 0.03456657,\n",
       "        0.03866396, 0.0480046 , 0.04172807, 0.03875192, 0.04527436,\n",
       "        0.03920764, 0.03616893, 0.03912233, 0.04617864, 0.03617301,\n",
       "        0.04333533, 0.04620508, 0.0449077 , 0.03181135, 0.0376677 ,\n",
       "        0.04102558, 0.04654696, 0.04247445, 0.04880312, 0.03841573,\n",
       "        0.04583797, 0.03170195, 0.04972637, 0.04022237, 0.04733939,\n",
       "        0.03344331, 0.0348214 , 0.0456328 , 0.04261265, 0.05207088,\n",
       "        0.04029809, 0.04629658, 0.04245073, 0.04380008, 0.03758723,\n",
       "        0.03662431, 0.03888905, 0.03734656, 0.04350155, 0.03706783,\n",
       "        0.04983858, 0.03865977, 0.05152776, 0.04883432, 0.0422343 ,\n",
       "        0.04420343, 0.04516349, 0.04656362, 0.03328513, 0.04968116,\n",
       "        0.04143425, 0.03852652, 0.04306257, 0.03812049, 0.04605049,\n",
       "        0.03959294, 0.03493796, 0.03126966, 0.03651774, 0.03921477,\n",
       "        0.0417807 , 0.03858992, 0.04028049, 0.04697921, 0.04867136,\n",
       "        0.04639876, 0.04442708, 0.04275143, 0.04638652, 0.04282024])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FNMetric.Test_tf(max_vectorize = 100)\n",
    "FNMetric.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FNMetric.Results[-1].result_value[\"metric_list\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting LR metric calculation...\n",
      "Running TF LR calculation...\n",
      "niter = 100\n",
      "batch_size = 100000\n",
      "The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.\n",
      "The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.\n",
      "LR metric calculation completed in 0.7082525580190122 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logprob_ref_ref_sum_list': array([-1419039.8019316 , -1418913.98855688, -1419453.14539668,\n",
       "        -1419657.94007585, -1419072.80338561, -1418166.07127097,\n",
       "        -1418445.77569241, -1418066.31072656, -1420256.07199453,\n",
       "        -1418044.87415222, -1419326.10428811, -1419326.79468731,\n",
       "        -1418314.87685254, -1419485.77321665, -1419486.5060734 ,\n",
       "        -1419137.3834325 , -1417497.50866623, -1418225.70604092,\n",
       "        -1417702.0206689 , -1418408.54553622, -1418236.22366223,\n",
       "        -1418143.74576535, -1418757.96197798, -1418426.18813946,\n",
       "        -1419838.98248408, -1417975.53278774, -1420127.35659578,\n",
       "        -1418535.63855344, -1419809.24815063, -1419369.3328283 ,\n",
       "        -1417814.76906265, -1419101.93050617, -1420028.26592495,\n",
       "        -1417599.81564845, -1418316.79226223, -1418881.96702154,\n",
       "        -1418806.45743903, -1418178.35037476, -1419176.85287023,\n",
       "        -1420120.32270562, -1419385.06816292, -1419556.98646649,\n",
       "        -1419336.28950425, -1419588.08286888, -1418472.32145843,\n",
       "        -1418947.2247593 , -1418670.9394032 , -1417883.16662006,\n",
       "        -1418628.2700319 , -1418729.89476722, -1418710.46924384,\n",
       "        -1418770.21723773, -1419152.3149339 , -1419446.82376623,\n",
       "        -1418529.52361861, -1417412.22098581, -1419691.13550013,\n",
       "        -1417915.70620165, -1418893.46146584, -1419458.38742629,\n",
       "        -1419174.89858006, -1418956.97583759, -1419308.76471113,\n",
       "        -1418633.26528998, -1420000.1924478 , -1420559.16304633,\n",
       "        -1419214.48810176, -1418746.8380508 , -1419092.44055359,\n",
       "        -1418621.89392612, -1418860.42523931, -1418380.70499157,\n",
       "        -1419529.27577777, -1418281.55360383, -1419025.39007214,\n",
       "        -1418727.0909169 , -1418458.06667901, -1419150.08277397,\n",
       "        -1418413.39798805, -1419127.91123062, -1419096.16105013,\n",
       "        -1419027.54409042, -1419649.19746405, -1418607.12604301,\n",
       "        -1419856.74730339, -1419537.13362527, -1419164.06431078,\n",
       "        -1418127.13693693, -1420275.70299415, -1418361.04086701,\n",
       "        -1420177.19500296, -1419497.80774459, -1418083.23534982,\n",
       "        -1417770.1034208 , -1419455.86171752, -1418138.13195315,\n",
       "        -1419992.15260702, -1417909.89410268, -1417492.30810359,\n",
       "        -1418900.49064768]),\n",
       " 'logprob_ref_alt_sum_list': array([-1419250.26369508, -1419651.17057521, -1420143.95648399,\n",
       "        -1419766.05000874, -1419871.203036  , -1419316.710644  ,\n",
       "        -1420239.38014946, -1418499.54584266, -1420348.79787725,\n",
       "        -1418590.20778014, -1418861.66845806, -1419765.43181661,\n",
       "        -1420123.63204325, -1419316.14276495, -1420454.58673807,\n",
       "        -1419501.55850149, -1419986.02398934, -1419911.55385299,\n",
       "        -1419780.34971307, -1418386.28747124, -1421661.85616187,\n",
       "        -1420323.85616427, -1419520.50027858, -1420077.22009649,\n",
       "        -1420242.70151066, -1419262.53412099, -1419828.58574394,\n",
       "        -1420135.22525105, -1420930.40114219, -1420188.18668686,\n",
       "        -1419637.78750589, -1420833.9499731 , -1419856.65059137,\n",
       "        -1420626.67459249, -1419909.51684966, -1420824.69654615,\n",
       "        -1421546.98737579, -1420534.61220608, -1420646.50769672,\n",
       "        -1418881.44652419, -1420492.66359756, -1418779.88002789,\n",
       "        -1419942.26173573, -1420278.5879099 , -1418966.00106695,\n",
       "        -1418762.31082481, -1420048.67958389, -1420077.65110678,\n",
       "        -1419827.95499742, -1419634.35497132, -1420593.18177428,\n",
       "        -1419362.7738899 , -1419213.61037277, -1419277.81468045,\n",
       "        -1420451.27292752, -1419682.70796322, -1419255.99068926,\n",
       "        -1418797.53058425, -1420362.67175757, -1419712.13316311,\n",
       "        -1417971.15121553, -1419974.64711354, -1418641.40395418,\n",
       "        -1420498.75232234, -1419182.22870868, -1420097.78163731,\n",
       "        -1419267.63810302, -1419612.18896971, -1420181.72014141,\n",
       "        -1419865.62874981, -1419283.00863172, -1419374.34559198,\n",
       "        -1420390.86408287, -1420039.88924306, -1420799.93420974,\n",
       "        -1421119.04042169, -1418803.09664281, -1420528.95872107,\n",
       "        -1419357.35272327, -1419600.95778155, -1419580.25378946,\n",
       "        -1419272.27665437, -1419381.38596726, -1419417.27999104,\n",
       "        -1419562.41902485, -1418600.44832709, -1419947.28374509,\n",
       "        -1419031.8767377 , -1420564.19259409, -1420420.16255517,\n",
       "        -1419964.37612779, -1418254.73936444, -1418731.21510608,\n",
       "        -1420139.72566068, -1421265.9158847 , -1418877.12439057,\n",
       "        -1418234.97053705, -1420341.15468479, -1420046.50402782,\n",
       "        -1419525.86263669]),\n",
       " 'logprob_alt_alt_sum_list': array([-1419246.63743935, -1419637.70850332, -1420130.79738314,\n",
       "        -1419760.72196282, -1419866.9944525 , -1419310.65639131,\n",
       "        -1420231.00784332, -1418494.39043948, -1420340.05812046,\n",
       "        -1418578.8937007 , -1418857.09919123, -1419759.2721784 ,\n",
       "        -1420115.86971596, -1419316.10089079, -1420451.32513427,\n",
       "        -1419496.6463944 , -1419977.80272067, -1419903.88054447,\n",
       "        -1419776.04485891, -1418383.55802969, -1421652.28052368,\n",
       "        -1420313.85973755, -1419518.74191177, -1420067.09847374,\n",
       "        -1420234.37620521, -1419259.45752923, -1419822.58832788,\n",
       "        -1420125.38911626, -1420919.70505597, -1420175.70709061,\n",
       "        -1419629.54581382, -1420832.51382396, -1419852.56650155,\n",
       "        -1420618.31018382, -1419904.86663982, -1420822.42563786,\n",
       "        -1421537.51657973, -1420522.43439968, -1420635.86703056,\n",
       "        -1418879.49523041, -1420484.75043972, -1418774.4364564 ,\n",
       "        -1419939.2593148 , -1420272.07473642, -1418960.91666094,\n",
       "        -1418755.18179971, -1420038.17040122, -1420067.15446888,\n",
       "        -1419820.77433028, -1419630.27197585, -1420590.21316532,\n",
       "        -1419355.64199953, -1419207.50880924, -1419272.19026515,\n",
       "        -1420445.0457467 , -1419674.02538585, -1419255.37375837,\n",
       "        -1418795.22327748, -1420353.12518528, -1419700.20324299,\n",
       "        -1417972.31145064, -1419967.98611334, -1418640.40970448,\n",
       "        -1420488.44254704, -1419176.80045132, -1420090.06961516,\n",
       "        -1419260.40928469, -1419606.843199  , -1420176.01280268,\n",
       "        -1419855.15885411, -1419273.22997838, -1419366.00985331,\n",
       "        -1420379.5259065 , -1420030.02810087, -1420791.62589123,\n",
       "        -1421108.75697849, -1418800.23211586, -1420519.23484958,\n",
       "        -1419348.74178589, -1419591.37407601, -1419568.61279359,\n",
       "        -1419268.70419959, -1419374.71154987, -1419409.12556604,\n",
       "        -1419557.40170722, -1418598.73675071, -1419948.64250292,\n",
       "        -1419026.46889269, -1420560.52508698, -1420409.23072483,\n",
       "        -1419966.13576995, -1418248.64788612, -1418721.78243779,\n",
       "        -1420137.31994165, -1421253.3422835 , -1418873.29751085,\n",
       "        -1418231.2519385 , -1420326.89408001, -1420036.2977704 ,\n",
       "        -1419519.85805021]),\n",
       " 'lik_ratio_list': array([ 7.25251144, 26.92414378, 26.31820169, 10.65609183,  8.417167  ,\n",
       "        12.10850538, 16.74461227, 10.31080636, 17.47951357, 22.62815889,\n",
       "         9.13853365, 12.31927641, 15.52465459,  0.08374832,  6.52320761,\n",
       "         9.82421418, 16.44253734, 15.34661703,  8.60970832,  5.45888308,\n",
       "        19.1512764 , 19.99285345,  3.51673361, 20.2432455 , 16.6506109 ,\n",
       "         6.15318353, 11.99483212, 19.67226958, 21.39217245, 24.95919249,\n",
       "        16.48338413,  2.87229827,  8.16817965, 16.72881733,  9.30041968,\n",
       "         4.5418166 , 18.94159213, 24.35561281, 21.28133232,  3.90258756,\n",
       "        15.82631567, 10.88714299,  6.00484185, 13.02634696, 10.16881203,\n",
       "        14.25805019, 21.01836534, 20.99327579, 14.36133428,  8.16599094,\n",
       "         5.93721793, 14.26378074, 12.20312705, 11.24883061, 12.45436165,\n",
       "        17.36515476,  1.23386178,  4.61461354, 19.09314459, 23.85984023,\n",
       "        -2.32047022, 13.32200039,  1.98849939, 20.61955062, 10.85651473,\n",
       "        15.42404429, 14.45763667, 10.69154142, 11.41467746, 20.9397914 ,\n",
       "        19.55730668, 16.67147734, 22.67635273, 19.72228438, 16.61663704,\n",
       "        20.56688639,  5.7290539 , 19.44774299, 17.22187475, 19.16741108,\n",
       "        23.28199173,  7.14490956, 13.3488348 , 16.30885002, 10.03463526,\n",
       "         3.42315277, -2.71751566, 10.81569003,  7.33501421, 21.86366068,\n",
       "        -3.5192843 , 12.18295665, 18.86533658,  4.81143807, 25.14720242,\n",
       "         7.65375945,  7.43719711, 28.52120957, 20.41251485, 12.00917297]),\n",
       " 'lik_ratio_norm_list': array([ 0.02293445,  0.08514162,  0.08322546,  0.03369752,  0.02661742,\n",
       "         0.03829046,  0.05295111,  0.03260563,  0.05527508,  0.07155652,\n",
       "         0.02889858,  0.03895697,  0.04909327,  0.00026484,  0.02062819,\n",
       "         0.03106689,  0.05199587,  0.04853026,  0.02722629,  0.0172625 ,\n",
       "         0.06056165,  0.06322295,  0.01112089,  0.06401476,  0.05265385,\n",
       "         0.01945807,  0.03793099,  0.06220918,  0.06764799,  0.0789279 ,\n",
       "         0.05212504,  0.009083  ,  0.02583005,  0.05290117,  0.02941051,\n",
       "         0.01436249,  0.05989857,  0.07701921,  0.06729748,  0.01234107,\n",
       "         0.0500472 ,  0.03442817,  0.01898898,  0.04119293,  0.03215661,\n",
       "         0.04508791,  0.06646591,  0.06638657,  0.04541453,  0.02582313,\n",
       "         0.01877513,  0.04510604,  0.03858968,  0.03557193,  0.03938415,\n",
       "         0.05491344,  0.00390181,  0.01459269,  0.06037782,  0.07545144,\n",
       "        -0.00733797,  0.04212786,  0.00628819,  0.06520474,  0.03433131,\n",
       "         0.04877511,  0.04571906,  0.03380962,  0.03609638,  0.06621743,\n",
       "         0.06184563,  0.05271984,  0.07170892,  0.06236734,  0.05254642,\n",
       "         0.06503821,  0.01811686,  0.06149916,  0.05446035,  0.06061268,\n",
       "         0.07362412,  0.02259419,  0.04221272,  0.05157311,  0.0317323 ,\n",
       "         0.01082496, -0.00859354,  0.03420221,  0.02319535,  0.06913897,\n",
       "        -0.01112895,  0.03852589,  0.05965743,  0.0152151 ,  0.07952244,\n",
       "         0.02420331,  0.02351848,  0.09019198,  0.06455004,  0.03797634])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRMetric.Test_tf()\n",
    "LRMetric.Results[-1].result_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.12641369, 39.68227   , 32.12422664, 34.5394083 , 18.02741861,\n",
       "       15.15680582, 15.52525829, 15.30709597,  8.02754197, 12.33412446,\n",
       "       22.37747   ,  8.27515184,  5.59264194, 22.24458832,  6.6707996 ,\n",
       "       32.74735999, 28.86028445, 13.11794732, 14.27299436, 22.86208402,\n",
       "       18.39920518, 21.32996565, 36.93012137, 20.1427733 , 17.57148818,\n",
       "       19.61003495, 29.95630618,  9.65594948, 11.22449692, 16.46875334,\n",
       "       27.37058086, 32.2727734 , 16.18983177, 28.2956806 ,  9.74557021,\n",
       "        0.96112609, 29.39248786, 34.58116667, 20.0009878 , 21.89585462,\n",
       "       20.80676864, 20.51842283, 11.02907168,  9.71282074, 40.61221184,\n",
       "       17.32039456, 16.68621792, 22.58762753, 26.75518011, 17.93928828,\n",
       "       23.70603449, 30.68736966, 35.55781733,  2.79771746, 21.9530251 ,\n",
       "       19.63178924, 12.22196435,  8.62642523, 22.14096932, 21.79869537,\n",
       "       27.26502374, 18.83945519, 25.834458  , 38.36558204, 37.8116679 ,\n",
       "       16.15533956, 21.92193098, 20.16993526, 48.23758029, 37.93297083,\n",
       "       21.25518577, 29.35963908, 29.38006424, 12.95584524, 36.18710029,\n",
       "       25.78357968, 18.77037509,  8.14676172, 19.33978936, 31.49589766,\n",
       "       26.921262  , 23.21965548, 31.61154519, 23.4497107 , 19.69164472,\n",
       "       44.96071852, 24.07007351, 20.86611637, 35.84555932, 36.53309175,\n",
       "       20.36906089, 23.31440371,  8.3644237 , 25.11429775, 20.22984536,\n",
       "       18.03076004, 28.19993993, 20.27445068, 17.23124832, 24.76102713])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRMetric.Results[-1].result_value[\"lik_ratio_list\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jetnet tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPD Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Starting FPD metric calculation...\n",
      "Running Jetnet FPD calculation...\n",
      "niter = 10\n",
      "batch_size = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_data/scratch/rtorre/anaconda3/envs/tf2_9/lib/python3.8/site-packages/jetnet/evaluation/gen_metrics.py:698: RuntimeWarning: Recommended number of samples for FPD estimation is 50,000\n",
      "  warnings.warn(\"Recommended number of samples for FPD estimation is 50,000\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPD metric calculation completed in 12.736108928918839 seconds.\n"
     ]
    }
   ],
   "source": [
    "d1 = TwoSampleTestInputs.dist_1_num.numpy().reshape(TwoSampleTestInputs.niter,TwoSampleTestInputs.batch_size,-1)\n",
    "d2 = TwoSampleTestInputs.dist_2_num.numpy().reshape(TwoSampleTestInputs.niter,TwoSampleTestInputs.batch_size,-1)\n",
    "print(\"------------------------------------------\")\n",
    "print(\"Starting FPD metric calculation...\")\n",
    "print(\"Running Jetnet FPD calculation...\")\n",
    "print(\"niter = 10\")\n",
    "print(\"batch_size = 10000\")\n",
    "start = timer()\n",
    "[JMetrics.fpd(s1,s2)[0] for s1,s2 in zip(d1,d2)]\n",
    "end = timer()\n",
    "print(f\"FPD metric calculation completed in {end-start} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPD Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Starting KPD metric calculation...\n",
      "Running Jetnet KPD calculation...\n",
      "niter = 10\n",
      "batch_size = 10000\n",
      "KPD metric calculation completed in 136.82288697501644 seconds.\n"
     ]
    }
   ],
   "source": [
    "d1 = TwoSampleTestInputs.dist_1_num.numpy().reshape(TwoSampleTestInputs.niter,TwoSampleTestInputs.batch_size,-1)\n",
    "d2 = TwoSampleTestInputs.dist_2_num.numpy().reshape(TwoSampleTestInputs.niter,TwoSampleTestInputs.batch_size,-1)\n",
    "print(\"------------------------------------------\")\n",
    "print(\"Starting KPD metric calculation...\")\n",
    "print(\"Running Jetnet KPD calculation...\")\n",
    "print(\"niter = 10\")\n",
    "print(\"batch_size = 10000\")\n",
    "start = timer()\n",
    "[JMetrics.kpd(s1,s2)[0] for s1,s2 in zip(d1,d2)]\n",
    "end = timer()\n",
    "print(f\"KPD metric calculation completed in {end-start} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
